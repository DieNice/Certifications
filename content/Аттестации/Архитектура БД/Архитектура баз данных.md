# Объекты базы данных
## Иерархия объектов в Postgres
Для понимания отношений и взаимодействий между объектами нужно разобраться, как организованы логические объекты в базе данных PostgreSQL. Базы
данных, роли, табличные пространства, настройки и процедурные языки находятся на одном уровне иерархии, как показано на рисунке ниже.

![[Pasted image 20221202115044.png]]

## **Шаблонные базы данных**
По умолчанию новая база данных создается как клон шаблонной базы данных template1. В шаблонной базе находятся таблицы, представления и функции, необходимые для моделирования отношений между пользовательскими объектами базы данных. Все они являются частью системной схемы pg_catalog.
 
По своей сути схема близка к понятию пространства имен в объектно ориентированных языках. Она используется для организации объектов базы данных,функциональности, прав доступа, а также для устранения конфилктов именю.

В postgresql  есть две шаблонные базы данных:
**template1:** база данных, клонируемая по умолчанию. Её можно модифицировать, тогда изменения будут отражены во всех вновь создаваемых базах. Например,  если вы собираетесь использовать во всех базах некоторое расширение , то  установите его в базу template1. Разумеется, это расширение не появится в уже существующих базах, но будет включено во все базы, созданные впоследствии.
**template0:** дополнительная база данных, у которой несколько задач:
- если template1 повреждена, то template0 можно использовать для её ремонта.
* она также полезна при восстановлении из резервной копии. Выгруженная база данных содержит, в частности, все расширения. Если расширение установлено в template, то при попытке восстановить копию в базу , созданную по этому шаблону. возникнет конфликт. А если перед восстановление создать базу по шаблону template0, то конфликтов не будет. Кроме того, template0, в отличии от template1, не содержит данных, зависящих от кодировки или локали.

## Таблицы
Таблицы используются для хранения данных. Вы можете иметь много таблиц в базе данных. Особенностью PostgreSQL является табличное наследование. Значения дочерней таблицы могут наследоваться от другой, родительской таблицы, поэтому при запросе данных из дочерней таблицы также отображаются данные из родительской.
![[Pasted image 20221201000005.png]]
Для каждой таблицы создаётся первичный дисковый файл кучи (heap), в котором хранится большая часть данных. Если в таблице есть столбцы с потенциально большими значениями, то также может быть и ассоциированный с этой таблицей файл TOAST, который используется для хранения слишком больших значений, не умещающихся в главной таблице. На каждую таблицу TOAST, если она существует, будет существовать один индекс. Также там могут быть и индексы, ассоциированные с базовой таблицей. Каждая таблица и индекс хранятся в отдельном дисковом файле — возможно более чем в одном файле, если размер этого файла превышает один гигабайт.

## Схемы
Схема — это логический контейнер таблиц и других объектов внутри базы данных. Каждая база данных PostgreSQL может иметь несколько схем. Важно отметить, что схемы являются частью стандарта ANSI-SQL.
Схема содержит все именованные объекты базы данных: таблицы, представления, функции, агрегаты, индексы, последовательности, триггеры, типы данных, домены и диапазоны. Одно и то же имя объекта может встречаться в разных схемах.
![[Схема.svg]]
![[Untitled Diagram.svg]]

![](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/postgresql-schema.png)

**Применение схем**
У схем есть несколько применений:
* Управление авторизацией - в многопользовательской среде схемы можно использовать для группировки объектов по ролям;
* Организация объектов базы данных - можно сгруппировать объекты в соответствии с бизнес-логикой. Например, выделить в отдельную группу исторические данные и данные аудита и завести для них специальную схему.
* Хранение стороннего SQL-кода - расширения, входящие в состав сторонних пакетов, могут использоваться в нескольких приложениях. Хранение их в отдельных схемах упрощает повторное использование и обновление.
**Пример создания схемы:**
```postgresql
create schema car_portal_app AUTHORIZATION car_portal_app;
```

## Табличные пространства
**Табличное пространство** — это место, где PostgreSQL хранит данные. Табличное пространство PostgreSQL позволяет легко перемещать данные в разные физически места с помощью простых команд. По умолчанию PostgreSQL предоставляет два табличных пространства: **pg_default** для хранения пользовательских данных и **pg_global** для хранения системных данных.

![](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/postgresql-tablespace.png)
Табличные пространства в Postgres позволяют администраторам организовать логику размещения файлов объектов базы данных в файловой системе. К однажды созданному табличному пространству можно обращаться по имени на этапе создания объектов.

Табличные пространства позволяют администратору управлять дисковым пространством для инсталляции Postgres. Это полезно минимум по двум причинам. Во-первых, это нехватка места в разделе, на котором был инициализирован кластер и невозможность его расширения. Табличное пространство можно создать в другом разделе и использовать его до тех пор, пока не появится возможность переконфигурирования системы.

Во-вторых, табличные пространства позволяют администраторам оптимизировать производительность согласно бизнес-процессам, связанным с объектами базы данных. Например, часто используемый индекс можно разместить на очень быстром и надёжном, но дорогом SSD-диске. В то же время таблица с архивными данными, которые редко используются и скорость к доступа к ним не важна, может быть размещена в более дешёвом и медленном хранилище.

**Пример**:
**Задача.** На HDD перестало хватать места под базу данных. Было принято решение добавить дополнительный HDD и перенести на него хранение одной таблицы cdr_old нашей базы данных.

**Решение.** Создаётся новое табличное пространство и в него переносится таблица cdr_old вместе с её индексами.

1.  Создадим новую (обязательную пустую) директорию на новом HDD. Права на директорию должны принадлежать пользователю, которому принадлежит сервер PostgreSQL.
    
    mkdir -p /var/log/VAR/LIB/psql/tspace_old_cdr
    chown -R postgres:postgres /var/log/VAR/LIB/psql/
    
2.  Создание табличного пространства tspace_old_cdr.
    
    CREATE TABLESPACE tablespace_name [ OWNER user_name ] LOCATION 'directory'
    
    tablespace_name - имя создаваемого табличного пространства. Имя не может начинаться с pg_ , такие имена зарезервированы для системных табличных пространств. user_name - имя пользователя владельца. directory - каталог, который будет использоваться для табличного пространства. В нашем случае команда примет вид:
    
    CREATE TABLESPACE tspace_old_cdr LOCATION '/var/log/VAR/LIB/psql/tspace_old_cdr';
    
3.  Перемещение таблицы cdr_old в новое табличное пространство. Перемещение табличных пространств означает простое (блочное) копирование данных на новое место HDD. Чем больше таблица, тем больше времени займет копирование. На время копирования таблица полностью блокируется (ACCESSEXCLUSIVELOCK).
    
    ALTER TABLE cdr_old SET TABLESPACE tspace_old_cdr;
    
    Перемещение индекса таблицы в новое табличное пространство.
    
    ALTER INDEX i_cdr_out SET TABLESPACE tspace_old_cdr;
    
    После окончания копирования, при помощи ключа \d, можно посмотреть в каком табличном пространстве находится таблица и ее индексы. Вывод команды ниже показывает, что сама таблица cdr_old и её индекс i_cdr_out находятся в одном табличном пространстве tspace_old_cdr, а три других индекса в табличном пространстве по умолчанию.
```
# \d cdr_old
...
Indexes:
	"cdr_new_pk" PRIMARY KEY, btree (id)
	"i_cdr_in" btree (begin_time, src_peer_id, cause_local)
	"i_cdr_out" btree (begin_time, dst_peer_id, cause_local), tablespace "tspace_old_cdr"
	"i_cdr_pairs" btree (begin_time)
Tablespace: "tspace_old_cdr"
``` 

Источники:
1. https://postgrespro.ru/docs/postgrespro/9.5/manage-ag-tablespaces
2. https://sysadminium.ru/tablichnye_prostranstva_v_postgresql/
3. https://postgrespro.ru/docs/postgrespro/9.5/manage-ag-tablespaces

## Процедуры и функции
PostgreSQL поддерживает хранимые процедуры и функции, чтобы обеспечить возможность повторного использования запросов SQL

Хранимые процедуры и функции похожи в том, что они написаны по определенной причине и могут использоваться везде, где они нужны. Однако между ними существуют различия — каждая из них подходит для определенных ситуаций:

-   Функции всегда возвращают одно значение — скалярное значение или таблицу. Хранимые процедуры могут возвращать ничего, одно значение или несколько значений.
-   Функции не могут включать инструкции DML, такие как UPDATE и INSERT. Хранимые процедуры могут включать любую инструкцию DML.
-   Функции не могут включать транзакции, а хранимые процедуры могут. Это ограничение означает, что функции не могут включать инструкции COMMIT или ROLLBACK.
-   Функции можно использовать в хранимых процедурах. Функция не может вызвать хранимую процедуру.

Хранимые процедуры добавлены в PostgreSQL относительно недавно, тогда как функции уже доступны в течение некоторого времени.

Создание хранимой процедуры для конкретной задачи имеет множество преимуществ, включая расширение функциональных возможностей базы данных Azure для PostgreSQL. Используйте хранимую процедуру, если вы хотите:

-   Разрабатывать и тестировать сложный код в одном месте, а затем вызывать его везде, где это необходимо.
-   Эффективно выполнять код. Хранимые процедуры, возвращающие одинаковый результат, более эффективны, так как они предварительно скомпилированы и хранятся на сервере Базы данных Azure PostgreSQL.
-   Сделать код более удобочитаемым.
-   Включить обработку ошибок в транзакцию.
-   Скрыть сложности от пользователей.
Хранимая процедура создается с помощью ключевых слов CREATE PROCEDURE. Кроме того, с помощью инструкции CREATE OR REPLACE PROCEDURE можно создать новую процедуру или заменить процедуру таким же именем.

Добавьте имя схемы, чтобы создать процедуру в определенной схеме. В противном случае она будет создана в текущей схеме. Имя процедуры должно быть уникальным в схеме, включая типы входных аргументов. Однако имена процедур можно перегружать, предоставляя одно и то же имя процедурам или функции с _разными_ типами аргументов.
```postgresql
CREATE PROCEDURE myprocedure (a integer, b integer)
    LANGUAGE SQL
    AS $$
        INSERT INTO mytable VALUES (a, b);
    $$;
```

Чтобы вызвать хранимую процедуру, используйте ключевое слово CALL. Входные параметры, которые были определены, нужно обязательно передать в хранимую процедуру, кроме тех параметров, которые не определены со значением по умолчанию.
```postgresql
CALL insert_data (1, 2);
```

## Функции
Функция — это многократно используемый блок кода SQL, который возвращает скалярное значение списка записей. В PostgreSQL функции также могут возвращать составные объекты.

![](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/postgresql-functions.png)
Функция возвращает одно значение. Ее можно использовать в инструкции SELECT.

Ниже приведен синтаксис для создания функции.
```postgresql
CREATE [OR REPLACE] FUNCTION
myfunction ([inputparam] type {default})
RETURNS returntype AS
$$
SQL body
$$
LANGUAGE 'language_name';
CREATE FUNCTION
```

Пример функции
```postgresql
create function sum_a() returns bigint as 
$$
	select sum(a) from t;
$$ language sql;

```

Пример вызова функции
```postgresql
select sum_a()
```

## Представления


Представление — это виртуальная таблица, которая используется для упрощения сложных запросов и обеспечения безопасности для набора записей. PostgreSQL также предоставляет вам обновляемые представления.

![](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/postgresql-views.png)

### Практическое использование view

-   Упрощают взаимодействие с базами данных. Можно заранее составить сложный по структуре запрос для создания представления и обращаться к нему при помощи простых запросов;
    
-   Представления можно объединять с другими таблицами или представлениями;
    
-   К представлениям можно обращаться из приложений;
    
-   Скрытие реализации реальных таблицы (принцип инкапсуляции);
Синтаксис:
```postgresql
CREATE [ OR REPLACE ] [ TEMP | TEMPORARY ] [ RECURSIVE ] VIEW имя [ ( имя_столбца [, ...] ) ]
    [ WITH ( имя_параметра_представления [= значение_параметра_представления] [, ... ] ) ]
    AS запрос
    [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]
```
CREATE VIEW создаёт представление запроса. Создаваемое представление лишено физической материализации, поэтому указанный запрос будет выполняться при каждом обращении к представлению.

Команда CREATE OR REPLACE VIEW действует подобным образом, но если представление с этим именем уже существует, оно заменяется. Новый запрос должен выдавать те же столбцы, что выдавал запрос, ранее определённый для этого представления (то есть, столбцы с такими же именами должны иметь те же типы данных и следовать в том же порядке), но может добавить несколько новых столбцов в конце списка. Вычисления, в результате которых формируются столбцы представления, могут быть совершенно другими.

Если задано имя схемы (например, CREATE VIEW myschema.myview ...), представление создаётся в указанной схеме, в противном случае — в текущей. Временные представления существуют в специальной схеме, так что при создании таких представлений имя схемы задать нельзя. Имя представления должно отличаться от имён других представлений, таблиц, последовательностей, индексов или сторонних таблиц в этой схеме.

### материализованные представления

В принципе это просто - если view выполняет реальный запрос каждый раз, когда идет запрос к view. То материализованные представления просто пересчитываются вами раз в некоторое время и работают по сути как таблицы.

Это очень удобно, чтобы подхачить и быстро решить вопрос с производительностью, но такая view в случае роста данных будет пересчитываться все дольше и дольше, даже в режиме конкурентности.

Пересчитать тоже можно по сути только всё разом. Блокировки всякие возникают. Как по мне минусов больше, чем плюсов, но если тупит прям здесь и сейчас, то это выход и очень полезный инструмент.

Короче говоря, мы у себя от них отказались так же быстро, как и ввели ) Все перевели на таблицы - они дают боле ожидаемое поведение. Могут включаться в другие VIEW, если надо, и обновляются на сколько точечно, на сколько вы сделаете.

```
 CREATE MATERIALIZED VIEW MV_MY_VIEW
 [ WITH (storage_parameter [= value] [, ... ]) ]
    [ TABLESPACE tablespace_name ]
     AS SELECT * FROM <table_name>;
```

Для поддержания актуальности данных необходимо передически обновлять материализованное представление.
```
REFRESH MATERIALIZED VIEW mymatview;
```

### Нематериализованные представления

Нематериализованное представставление каждый раз при обращении к нему выполняет запрос, который его формирует. Таким образом нематериализованное представление не имеет физических данных в отличии от материализованных представлений.


пересчёт представлений

```
REFRESH MATERIALIZED VIEW [ CONCURRENTLY ] имя
    [ WITH [ NO ] DATA ]
```

REFRESH MATERIALIZED VIEW полностью заменяет содержимое материализованного представления. Эту команду разрешено выполнять только владельцам мат. представления. Старое его содержимое при этом аннулируется. Если добавлено указание WITH DATA (или нет никакого), нижележащий запрос выполняется и выдаёт новые данные, так что материализованное представление остаётся в сканируемом состоянии. Если указано WITH NO DATA, новые данные не выдаются, и оно оказывается в несканируемом состоянии.

Указать CONCURRENTLY вместе с WITH NO DATA нельзя.

### индексы в представлениях
view не хранит никаких данных, а раз нет данных - то не по чему строить индекс.
Пример принципиальной проблемы индекса на view: если сделать view вида select foo, avg(bar) from tablename group by foo; - как пересчитывать данные при изменении строк в tablename?
Индекс может быть создан на материализованном представлении (materialized view) - потому что такое представление данные хранит непосредственно. Но обновлять эти данные требуется вручную запросом REFRESH MATERIALIZED VIEW, который выполнит запрос, запишет его результат в новый heap, затем заменит старый heap новым (если не указан concurrently) либо обновит несовпадающие строки (для concurrently).



##  Приведения

Приведения позволяют вам преобразовать один тип данных в другой. Приведения фактически осуществляются за счет специальных функций для выполнения преобразований. Вы также можете создать свои собственные преобразования, чтобы переопределить приведение предоставляемое PostgreSQL по умолчанию.

## Последовательности
Последовательности используются для управления столбцами с автоинкрементом, которые определены в таблице, как **SERIAL**.

![](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/postgresql-sequence.png)

## Расширения
Начиная с версии 9.1, PostgreSQL ввел концепцию расширений для объединения в один модуль других объектов, включая типы, приведения, индексы, функции и т.д. Цель расширений — облегчить поддержку.

![](https://www.postgresqltutorial.com/wp-content/uploads/2019/05/postgresql-extension.png)

# Нормализация данных
...

# Структура таблиц
Таблицы и индексы хранятся в виде коллекции страниц размером 8 КБ.

Страницы таблиц и индексов содержатся в одной или нескольких секциях. **_Секция** — это пользовательская единица организации данных_. По умолчанию таблица или индекс имеет единственную секцию, которая содержит все страницы таблицы или индекса. Секция располагается в одной файловой группе. 

Если таблица или индекс используют несколько секций, данные секционируются горизонтально, так что группы строк сопоставляются отдельным секциям, основываясь на указанном столбце. Секции могут храниться в одной или нескольких файловых группах в базе данных. Таблица или индекс рассматриваются как единая логическая сущность при выполнении над данными запросов или обновлений. Секция состоит из фрагментов одного или нескольких файлов. Данные внутри фрагмента файла представляются в виде кучи (строки данных хранятся без определенного порядка – последовательное размещение) или сбалансированного дерева.

## Организация таблицы
Следующая иллюстрация показывает организацию таблицы

![Физическая структура таблицы в базе данных SQL Server](https://intuit.ru/EDI/06_05_18_2/1525558963-18645/tutorial/531/objects/10/files/10_04.gif)
Физическая структура таблицы в базе данных

Каждая секция содержит строки данных либо в куче, либо в структуре кластеризованного индекса. Кластеризованный индекс реализуется в виде структуры индекса сбалансированного дерева, которая поддерживает быстрый поиск строк по их ключевым значениям. Страницы в каждом уровне индекса, включая страницы данных на конечном уровне, связаны в двунаправленный список. Однако перемещение из одного уровня на другой выполняется при помощи ключевых значений.

## Куча
**_Куча** — это последовательность строк таблицы, которые не имеют кластеризованного индекса_. Строки данных хранятся без определенного порядка, и какой-либо порядок в последовательности страниц данных отсутствует. Страницы данных не связаны в связный список.

В Postgres есть механизм, который называется вакуум (VACUUM). Он перераспределяет данные (вычищая мертвые записи) и привнося небольшой хаос в строки.

## Page
При вставки какой-либо строки в Postrgres выделяется минимально атомарная единица хранения информации - **Page** и он всегда равен 8Кб (можно настраивать).

## Представление Журналируемой таблицы
Журналируемые таблицы работают следующим образом: 
Имеется уровень представления (view, meta view) - Концептуальный.
Логический уровень представления.
Физический уровень представления.

![[Pasted image 20221202111415.png]]
Одна таблица на уровне метаданных соответствует нескольким файлам на уровне операционной системы, а суффикс помогает упорядочить назначение контента.

## Структура Page
![[Pasted image 20221202112502.png]]
Структура пейджа сильно напоминает используемую в Oracle и в MysQL. Эти структуры одновременно растут сверху вниз и снизу вверх. Когда вы делаете инсерты, рождаются T1, T2, Т3 или tuples, которые записываются снизу налево. Они растут до тех пор, пока не встретятся где-то ближе к началу пейджа со значениями поинтеров (I1, I2, I3). 

Поинтеры — это указатели на конкретные tuples, которые хранятся ниже в файле. Эта структура прошла огонь, воду и медные трубы с точки зрения оптимизации и правильного хранения информации. Она помогает оптимизатору Postgres использовать ее преимущества в плане работы с оффсетами и указателями. 

У пейджа есть header — это метаслой, который хранит интересную структуру, показывающую общее количество места в пейдже. Также в структуре пейджа есть указатели по транзакциям, метаслой для каждого tuple, для каждой строки. Есть special-зона, но она не используется для стандартных таблиц, так как не необходима для индексных структур. Почему? Потому что этот пейдж является атомарным элементом не только для таблиц, но также и для индексов. Одна общая структура подведена под всевозможные хранения. 

У пейджа есть Fillfactor, о нем мы подробнее поговорим дальше. По умолчанию Fillfactor стоит на 100% и означает, что Postgres будет максимально заполнять ваш пейдж до конца. Что значит максимально заполнять? Грубо говоря, пока нижняя зона (lower) не встретится с верхней (upper). Как только они соприкоснутся, будет рожден новый пейдж. Ситуация будет повторяться до тех пор, пока не заполнятся 8 килобайт, потом родятся следующие 8 килобайт и так далее. Так растет табличка.
![[Pasted image 20221202113638.png]]
## Tuple
![[Pasted image 20221202113703.png]]
Если посмотреть не на метаданные, а на саму строку, которая находится внутри, мы можем увидеть интересные атрибуты относительно не только длины самого тапла (tuple), но также по номеру транзакции, которая была применена. 

Наша строка (T1) весит 42 байта. Как это все хранится? Дело в том, что каждая строка также хранит метаслой, метаданные. Эти 42 байта разделяются на две части. Первая часть — это структура, нарисованная слева на рисунке 11. , Она определяет размер байт для хранения каждого поля этих метаданных. С другой стороны у нас есть tuple-данные (пользовательские данные), и они равны 18 байтам. Получается, у нас 18 из 42 байт — это пользовательских данные. Обратите внимание, что метаданные настолько важны, что отжирают столько места.

Другой срез метаданных - это CTID — пойнтер (pointer), который содержит адрес страницы плюс адрес tuple (строки) внутри этой страницы.
![[Pasted image 20221202113859.png]]
Эта структура очень напоминает массив, рекорд (запись), который указывает что эта строка “1 1 string #1” хранится в нулевом пейдже в первом tuple. Если мы добавим сюда OID-отношения, то по сути получим координаты поиска информации. С одной стороны, у нас есть дата-файл, с другой — у нас есть пейдж в этом дата-файле, и, с третьей стороны, у нас есть tuple, куда нужно точечно получить эту информацию из конкретного пейджа. На этом принципе строятся btree-индексы, когда листья в этом btree-индексе указывают на конкретный ctid, указанный в конкретном файле.

## TOAST-таблицы

Посмотрим на TOAST-таблицы или так называемые таблицы-спутники. Смысл в том, что это табличка-спутник, которая помогает вам сплитить (SPLIT) данные с точки зрения длины строк. TOAST-таблица — это обычная Heap-таблица, и она, по сути, наследует в себе те свойства, которые вы указываете на оригинальной таблице.
![[Pasted image 20221202114322.png]]
Если мы рассмотрим нашу табличку (t), мы увидим слева ссылку на нашу табличку 16559 — это идентификатор таблицы, сохраняющейся в метаслое.
Еще стоит обратить внимание, что TOAST-таблица не содержит ссылку на другой TOAST. То есть нет бесконечного числа тостов, есть первый уровень и все.
![[Pasted image 20221202114430.png]]
Данные в toast-таблице разделены на чанки (chunk), и каждый чанк содержит свою часть метаданных. По сути они разделены. Что это значит? Делая запрос “SELECT ctid, * FROM table”, вы заставляете Postgres (если у вас есть длинные строки) обращаться к TOAST-таблице, вычитывать эти чанки, склеивать их для вас, и возвращать эту информацию наружу. Мое личное мнение: если вы делаете SELECT ctid со звездочкой — остерегайтесь звездочки и указывайте, какие столбцы вы хотите. Скорее всего, в большинстве случаев вам не понадобятся длинные строки. Но когда нужны именно длинные строки, то Postgres работает так: он сплитит ваши данные и сохраняет их в отдельной структуре, помогающей функционировать оригинальной таблице.

***Отметим, что TOAST работает только для таблиц, но не для индексов***. Это накладывает ограничение на размер индексируемых ключей.

### Стратегии хранения таблицы TOAST

Для хранения столбцов на диске применяются четыре различные стратегии, которые могут использовать методику TOAST. Они представляют различные сочетания сжатия и внешнего хранения. Стратегию можно задать на уровне типа данных и на уровне столбцов.

-   **Обычная (PLAIN)** стратегия предотвращает сжатие или внешнее хранение. Она отключает использование однобайтовых заголовков для типов varlena. Обычная стратегия возможна только для столбцов с типами данных, которые не поддерживают TOAST.
-   **Расширенная (EXTENDED)** стратегия допускает как сжатие, так и внешнее хранение. Она используется по умолчанию для большинства типов данных, которые поддерживают TOAST. Сначала выполняется попытка сжатия. Если строка является по-прежнему слишком большой, предпринимается попытка использовать внешнее хранение.
-   **Внешняя (EXTERNAL)** стратегия допускает внешнее хранение, но не сжатие. При применении внешней стратегии подстрочные операции в больших текстовых и байтовых столбцах выполняются быстрее. Но дисковое пространство будет увеличено, так как эти операции оптимизированы для получения только необходимых частей внешнего значения, когда оно не сжимается.
-   **Главная (MAIN)** стратегия допускает сжатие, но не внешнее хранение. Внешнее хранение по-прежнему выполняется для таких столбцов, но только в качестве последнего средства. Это происходит, когда нет другого способа сделать строку достаточно маленькой, чтобы поместить ее на странице.

### Использование стратегий хранения таблицы TOAST

Если ваши запросы получают доступ к типам данных, которые поддерживают TOAST, рассмотрите возможность использования основной стратегии вместо расширенной (по умолчанию), чтобы уменьшить время выполнения запросов. Основная стратегия не исключает внешнее хранение. Если ваши запросы не получают доступ к типам данных, которые поддерживают TOAST, может быть полезно оставить расширенную стратегию. Большая часть строк главной таблицы поместится в общий буферный кэш, что способствует повышению производительности.

При наличии рабочей нагрузки, использующей схему с широкими таблицами и большим количеством символов, рассмотрите возможность применения таблиц TOAST PostgreSQL. Например, таблица клиентов содержит больше чем 350 столбцов с несколькими столбцами, в которых есть 255 знаков. После перехода на основную стратегию таблицы TOAST время выполнения запроса сократилось с 4203 до 467 секунд, что на 89 процентов больше.

Каждый тип данных, совместимый с TOAST, определяет стандартную стратегию для столбцов этого типа данных, но стратегия для заданного столбца таблицы может быть изменена с помощью `ALTER TABLE SET STORAGE`.

# Типы таблиц в PostgreSQL: clustered, foreign, partitioned и inherited tables

## Clustered tables — кластеризованные таблицы
Мало кто любит хаос, всем нравится порядок. В рамках реляционных баз данных понятие хаоса тесно переплетено с хранением информации, потому что на протяжении своего жизненного цикла таблица постоянно видоизменяется. 

В процессе работы с РСУБД на уровне диска происходит постоянное изменение  содержимого таблицы. Например, вы обновили данные и ваша обновлённая строка попала на другую страницу таблицы (тут надо оговориться про [FILLFACTOR](https://habr.com/ru/company/quadcode/blog/671254/)) с появлением мёртвой записи (dead tuple) в текущей позиции. Затем autovacuum-процесс удалил мёртвую запись, и освободившийся слот заполнился вновь поступившей строкой. Простой тест, который вы сами можете провести. Сделайте следующие команды в обычную вновь созданную таблицу:

```postgresql
INSERT INTO test(id,name) VALUES(1, 'Петр');
INSERT INTO test(id,name) VALUES(2, 'Иван');
INSERT INTO test(id,name) VALUES(3, 'Сергей');
```

После выполнения SQL запроса (прошу заметить, тут нет `ORDER BY`):

```postgresql
SELECT *
   FROM test;
```

Вы увидите выборку в одном порядке:

Но сделав обновление строки

```postgresql
UPDATE test
       SET name = 'Руслан'
WHERE id = 2;
```

и затем выполнив тот же самый SQL, вы получите выборку в другом порядке:
Порядок строк изменился! Энтропия выросла.

А теперь представьте, что вы ищете в таблице данные, например, цифру 4. Как это сделать в рамках хаотической зелёной топологии, которую я нарисовал ниже слева? Только перебирая запись за записью: вы случайно тыкаете в какой-то номер и сравниваете его с нужной цифрой 4. По сути, придётся перебрать все записи, потому что цифр 4 может быть несколько. Другими словами, нужно последовательное сканирование. 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ef6/911/4c8/ef69114c8df022c550973e2a51944692.png)

Но когда у вас есть порядок, как в таблице справа, вы будете четко знать, что цифра 4 лежит между 3 и 5. В этом весь смысл организации порядка и кластеризованных таблиц: они помогают создать упорядоченную структуру из хаоса. Если вы произвольно выбираете случайную позицию в упорядоченной синей таблице в поисках цифры 4, то возможны три исхода:

-   Число равно нужному.
    
-   Число меньше нужного.
    
-   Число больше нужного. 
    

Это даёт большое преимущество в скорости выполнения поиска. Если число больше 4, вы дальше пойдёте в поисках вверх по таблице. Если меньше — пойдёте вниз. Или вы сможете получить диапазон и искать цифру 4 внутри него. Это гораздо быстрее, чем поиск по всем данным, как было в неорганизованной зелёной топологии — а именно в логарифм раз быстрее. 

Рассмотрим пример создания кластеризованной таблицы:

```postgresql
CREATE TABLE test.cluster_table
(id       INTEGER,
 name VARCHAR) WITH (FILLFACTOR = 90);

CREATE INDEX id_idx ON test.cluster_table (id);

CLUSTER [VERBOSE] test.cluster_table USING id_idx;
```

Здесь я создал таблицу с названием cluster_table и установил для неё значение  `FILLFACTOR` в 90% — это [процент заполняемости](https://habr.com/ru/company/quadcode/blog/671254/). Он никак не влияет на нашу кластеризованную таблицу, это просто пример того, как можно установить свойство при создании таблицы этого типа. Дальше создаю BTree индекс на таблицу `CREATE INDEX` на поле id и вызываю команду `CLUSTER`. Команда `CLUSTER` делает кластеризацию таблицы, используя индекс, который мы предварительно создали. 

Здесь важно знать, что пока кластеризация не пройдёт до конца, все текущие транзакции в таблице будут заблокированы. Блокировка трафика происходит потому, что Postgres пытается перестроить таблицу в том порядке, который вы требуете на основании индекса. И после создания этого порядка Postgres должен сохранить его в другой файл. По сути, это операция миграции данных на уровне диска с одного файла в другой, но только в указанном порядке. Данные должны размещаться на основании индекса, в нашем случае по полю id. Я образно показал это на рисунке ниже, обратившись к метаданным до и после выполнения кластеризации таблицы.

Изначально таблица размещалась в  файле с номером 45969. После команды `CLUSTER` имя файла поменялось. Произошло перемещение данных из одного файла в другой. Поэтому происходит блокировка, и, соответственно, входящий трафик не может использовать эту таблицу до тех пор, пока она не станет доступна.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/3f8/d81/892/3f8d81892c3fbe18d37e32aed7c4b791.png)

Вы можете также создать индекс для последующей кластеризации, который содержит много столбцов (multicolumn index), либо указать убывающий порядок по тем или иным столбцам (DESC / ASC). 

Можно по желанию использовать команду `CLUSTER VERBOSE`, которая возвратит детализацию того, что сделал PostgreSQL, а именно сколько было страниц, какие страницы были перемещены и так далее. 

### Тест-кейсы и порядок в данных

Проведём небольшой тест: 

```postgresql
CREATE TABLE test.cluster_table
(id       INTEGER,
 name VARCHAR) WITH (FILLFACTOR = 90);

CREATE INDEX id_idx ON test.cluster_table (id);

INSERT INTO test.cluster_table
  SELECT (random( )*100)::INTEGER,
                 'test'
     FROM generate_series(1,100) AS g(i);

SELECT id
   FROM test.cluster_table;
```

Создадим таблицу, индекс по полю id и затем сгенерируем 100 произвольных строк, используя команду generate_series. В результате получились неупорядоченные данные:

![[Pasted image 20230209170202.png]]
Чтобы добиться порядка при выводе, надо добавить ключевое слово ORDER BY. Но здесь важно помнить, что операция `ORDER BY` тоже требует ресурсов и за неё следует заплатить. Каждая наносекунда на счету при высоконагруженном трафике, а тут ещё сортировка.

В этом случае давайте сделаем кластеризацию таблицы командой `CLUSTER VERBOSE`, используя индекс, который я заранее создал:

```postgresql
CLUSTER VERBOSE test.cluster_table USING id_idx;

SELECT id
   FROM test.cluster_table;
```

Вуаля, данные отсортированы без сортировки:

![[Pasted image 20230209170244.png]]

Но здесь есть ловушка. Сделаем обновление всех строк — а на самом деле достаточно изменить значение у одной строки.

```postgresql
UPDATE test.cluster_table
       SET id = id * (random( )::INTEGER);

SELECT id
   FROM test.cluster_table;
```

В нашу кластеризованную таблицу при этом вернётся хаос:

![[Pasted image 20230209170309.png]]

Чтобы вернуть порядок обратно, потребуется снова выполнить команду `CLUSTER`. Можно даже не указывать повторно индекс, потому что он сохранился в метаданных PostgreSQL. И база данных в следующий раз будет понимать, на основе чего вы делаете кластеризацию:

```postgresql
CLUSTER VERBOSE test.cluster_table;


SELECT id
   FROM test.cluster_table;
```

Вы сможете снова наблюдать порядок только после команды `CLUSTER`. Это ахиллесова пята кластеризованных таблиц: любое изменение ключа кластеризации может сразу принести беспорядок в данные. 

### Когда подойдёт кластеризованная таблица

Кластеризованные таблицы подойдут, если ваши данные — это таблицы-справочники (ну или SCD — Slowly Changing Dimension), например адресная система. Этот тип таблиц удобен в случае, если вы загружаете новые данные достаточно редко, например, раз в месяц. 

Если таблица очень часто меняется и подвержена INSERT-, UPDATE- и DELETE-операциям, кластеризовать её придётся постоянно, а это не очень удобно и вообще критично. Цель кластеризации — избегать ненужных `ORDER BY` в постоянных запросах к таблице по кластеризованному полю или полям. 

### Метаданные кластеризованной таблицы

По метаданным кластеризованной таблицы можно понять, что она кластеризована:

```postgresql
SELECT  c.oid AS "OID",
        c.relname AS "Relation name"
  FROM pg_class c INNER JOIN pg_index i ON i.indrelid = c.oid
WHERE c.relkind = 'r' AND 
      c.relhasindex AND 
      i.indisclustered;
```

| **OID** |  **Relation name** |
|-----|-----------------|
|45969 | cluster_table | 

Значение “true” в поле relhasindex  указывает, что есть индекс для поддержки кластеризации. Когда мы перестроим кластер в следующий командой `CLUSTER`, то  PostgreSQL будет использовать указанный индекс из метаданных.

## Foreign tables — внешние таблицы

Внешние таблицы в PostgreSQL полезны с точки зрения быстрого получения данных из другого источника, если у вас есть возможность к нему присоединиться. Кроме того, если повозиться, то можно обеспечить так называемый жизненный цикл данных — обеспечить метрику Retention Policy. Здесь вам может помочь следующий набор инструментов: VIEW ( виртуальная таблица) + набор обычных таблиц, разделённых логикой сохранения данных (POOD-дизайн) с актуальными данными + внешние таблицы,  которые ориентируются на файлы,  хранящие данные вне базы данных на более дешевых дисках (тут как раз старые данные, превысившие метрику Retention Policy).

Внешних таблиц и типов соединений — много, например: 

-   CSV-файл. 
    
-   Соединение со многими другими РСУБД.
    
-   Соединение с некоторыми noSQL БД.
    

Рассмотрим пример внешней таблицы, основанной на CSV-файле. В этом нам поможет расширение file_fdw, основанное на fdw — foreign data wrapper:

```postgresql
CREATE EXTENSION file_fdw;

CREATE SERVER csv_log FOREIGN DATA WRAPPER file_fdw;

CREATE FOREIGN TABLE test.csv (
  id       INTEGER,
  name VARCHAR
) SERVER csv_log 
  OPTIONS (filename '/var/lib/postgresql/file.csv', 
                   delimiter ';', format 'csv');
```

Создаю внешнюю таблицу и описываю атрибуты, указывая сервер для fdw, который заранее создал с опциями работы с файлом.

Если я сделаю SQL-запрос к внешней таблице, то увижу данные, которые представлены в файле. Так как внешняя таблица зарегистрирована (в смысле имеется запись в метаданных PostgreSQL), то у меня возникает гипотеза: а не хранятся ли данные не во внешнем файле, а в файле данных PostgreSQL? 

```postgresql
SELECT  oid AS "OID",
        pg_relation_filepath(oid) AS "File path",
        pg_relation_size(oid) AS "Relation Size"  
  FROM pg_class
WHERE relname = 'csv';
```

Результат выполнения:

|**OID**|**File path**|**Relation size**|
|----|---------|
|46003| _null_| 0|

Итак, внешняя таблица как объект зарегистрирована в метаданных (имеется OID идентификатор объекта), но вот соответствующего файла данных нет, то есть данные представлены только во внешнем источнике.

### Запросы к внешним таблицам

Каким образом работают запросы к внешним таблицам? Посмотрим на примере CSV-файла. 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b2c/672/25f/b2c67225fb8d1321fae154748b6e5249.png)

Пока данные подгружаются, происходит достаточно длительная задержка по времени, поэтому храним старые данные где-то на старых дисках. Для получения данных надо открыть дескриптор внешнего файла, потом скопировать данные в память или во временный файл и вернуть данные нам. Если мы чуть позже перевыполним тот же запрос, то ускорения не предвидится: процесс остается аналогичным.

Существует великое множество библиотек внешних таблиц для разных нужд. Например, postgres_fdw. С её помощью мы можем соединяться с PostgreSQL из PostgreSQL. Это очень сильно напоминает database link:

```postgresql
CREATE EXTENSION postgres_fdw;

DROP FOREIGN TABLE test.csv;

CREATE SERVER pg_log FOREIGN DATA WRAPPER postgres_fdw
OPTIONS (host '192.168.56.10', port '5432', dbname 'course_db');

CREATE USER MAPPING FOR test SERVER pg_log 
OPTIONS (user 'test', password 'test');

CREATE FOREIGN TABLE test.csv (
  id       INTEGER,
  name VARCHAR
) SERVER pg_log 
  OPTIONS (schema_name 'test', table_name 'user');
```

Огромное [количество библиотек](https://wiki.postgresql.org/wiki/Foreign_data_wrappers) доступно для работы с внешними источниками. Например:

-   Oracle, MySQL, SQLite, MS SQL Server, Sybase.
    
-   Cassandra, MongoBD, HBase, Redis, Neo4j.
    
-   Twitter, Telegram.
    
-   JSON, XLM, GeoFiles, LDAP. 
    

### Метаданные внешней таблицы

Как мы выяснили, внешняя таблица как объект фиксируется в метаданных:

```postgresql
SELECT  oid AS "OID",
        relname AS "Relation name",
        CASE
          WHEN relpersistence = 'p' THEN 'Permanent'
          WHEN relpersistence = 't' THEN 'Temporary'
          ELSE 'Unlogged'
        END AS "Type",
        relkind AS "Subtype"
   FROM pg_class
WHERE relname = 'csv';
```

|**OID**|**Relation name**|**Type**|**Subtype**|
|-|-|-|-|
|46003|csv|Permanent|f|

Она является постоянной таблицей (удивительно), но у неё имеется указатель “f” — это подтип отношения. И он указывает, что-то наша таблица — foreign, то есть внешняя.

## Partitioned tables — партицированные таблицы

Смысл партицированных таблиц лучше всего характеризует крылатое выражение «разделяй и властвуй». Вносить изменения в большую монолитную таблицу реляционной базы данных тяжело и больно из-за ACID. Если вы хотите сделать изменения структуры, например добавить новый столбец, то вся большая таблица заблокируется, пока столбец не будет добавлен. Грубо говоря, файл, который соответствует этой таблице, должен быть перестроен. 

В этом случае разделение на партиции, на части данных — это как раз механизм «разделяй и властвуй». Управлять конкретными частями легче, чем монолитом. Это пример а-ля микросервисной архитектуры на уровне баз данных: каждая часть ничего не знает о других. Партиции управляются координатором, а координатор — это мастер-таблица или хаб-таблица, которая распределяет входящие данные между частями:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/915/d6a/f95/915d6af95a1822036fe6e8f62c9c9ee7.png)

### Политики работы с партициями 

Есть три основные политики работы с партициями в реляционных базах данных:

-   Партицирование по списку.
    
-   Партицирование по диапазону.
    
-   Партицирование по хешу. 
    

Вы можете партиционировать данные по списку. Например, положить в одну партицию данные по городам Казань, Москва, Мурманск, в другую — данные по Новгороду, Петербургу и Набережным Челнам, а в третью — по Иркутску, Самаре и Новосибирску. Тем самым у вас будут разделены части данных по ключу партиции, который соответствует списку этих значений. На рисунке я указал распределение данных, потому что это очень важно в рамках нагрузок на конкретную партицию. 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/425/11e/30b/42511e30b542ca6af4dd7d91028ee153.png)

Партицированные таблицы — это шаг к шардированию таблицы, когда разделение данных таблицы происходит между серверами. Партиция — это разделение таблицы на уровне одной базы данных или вертикально, шардирование — это разделение между базами данных или горизонтально.

Если вы неправильно выбрали ключ партиции, другими словами неправильно в своём логическом дизайне разделили данные, то эта логика может сильно влиять на физический мир использования ваших данных. Например, большее количество записей по [Казани, Москве и Мурманску], чем записей по [Новгороду, Набережным Челнам и Петербургу]. С точки зрения работы с данными это означает, что с большей частотой будут приходить SQL-запросы, нагружающие первую партицию больше, чем остальные.

Как раз для такого уровня разделения есть понятие хеша или хеш-функции, которая равномерно «размазывает» данные по партициям. Тем самым у вас снимается вопрос по распределению данных. Но и здесь есть свой минус — при распределении по хэш-функции вы можете делать поиск на равенство по партицированному ключу, чтобы добиться оптимизации.

Есть и другие стратегии разделения данных на партиции. Они являются гибридными: либо одновременно по диапазону и хэшу, либо по списку и диапазону. 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/95c/104/a12/95c104a128f4a7fb03fdf517df4df107.png)

### Примеры создания партицированных таблиц с разными политиками

**Партицирование по диапазону.** Создадим разделённую по диапазону таблицу part:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/f52/ef1/21c/f52ef121cdd368b518c99b4d3794bffa.png)

К ней я добавляю две подчинённые таблицы: part_1 и part_2, которые являются партициями для моей основной таблицы. И указываю для них диапазон хранения: от 10 до 19 или от 0 до 9. Мой ключ распределения данных — это атрибут id. Если выполнится `INSERT` со значением id = 2, то он попадёт в part_2, если придёт INSERT со значением id = 12, то он попадёт в part_1. Обратите внимание, что число 9 и 19 не входят в правую границу диапазона (выколотая точка). 

**Партицирование по списку.** Другой пример — разделение партиций по списку:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/31f/251/ecb/31f251ecb7b82ea947ae7f7770118bf5.png)

Тут уже нет никаких выколотых границ, список чётко регламентирует значения поля id.

Партицирование по хешу. Можно сделать партицирование по хешу:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/8f9/a11/9dd/8f9a119dd7c4463b35fdd90e9418bd3a.png)

Я создал две хеш-таблицы. Деление по модулю 2 должно вернуть либо остаток, либо его отсутствие. Хеш у меня рассчитывается с использованием функции PostgreSQL mod(Hash(id),2). Если ответом будет 1, то данные попадут в hash_2, если будет 0 — то в hash_1. 

**Партицированная топология.** Можно создать партицированную топологию — партиции и подпартиции:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/fd7/cd5/f7e/fd7cd5f7ee5e4c37690f476c500c6d51.png)

Под основной мастер-таблицей находится другая hub-таблица, которая в свою очередь разделяет данные по подпартициям.

Обратите внимание, что в одной из подпартиций есть слово `DEFAULT`. Оно означает, что эта подпартиция используется для нераспознанного значения партицированного атрибута, которое не подходит ни в один из списков других партиций. DEFAULT-партиция нужна для того чтобы, например, иметь буфер для возможных ошибочных данных, не предусмотренных или забытых в логике работы, чтобы в будущем стабилизировать ваш код. В противном случае, когда к вам придёт значение, не удовлетворяющее условиям всех партиций, то на уровне бэкенда вы получите «недоумение» от базы данных: «Я не знаю, куда его сохранять». Такие записи будут сохраняться как раз в DEFAULT-партицию. 

Приведу пример хеш-топологии. Я делаю таблицу hash партицированной по hash(id) и создаю десять партиций с указанием модуля 10 и остатком от 0 до 9:

```
CREATE TABLE test.hash (id INTEGER) PARTITION BY hash(id) ;

CREATE TABLE test.hash_1 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 0);
CREATE TABLE test.hash_2 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 1);
CREATE TABLE test.hash_3 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 2);
CREATE TABLE test.hash_4 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 3);
CREATE TABLE test.hash_5 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 4);
CREATE TABLE test.hash_6 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 5);
CREATE TABLE test.hash_7 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 6);
CREATE TABLE test.hash_8 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 7);
CREATE TABLE test.hash_9 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 8);
CREATE TABLE test.hash_10 PARTITION OF test.hash 
  FOR VALUES WITH (MODULUS 10, REMAINDER 9);
```

Визуально топология зависимостей будет выглядеть как на рисунке ниже.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/70e/420/9ff/70e4209ff9ff60edbca2451686794b00.png)

С точки зрения работы с данными мы можем делать запрос к конкретной партиции с помощью  SELECT * FROM hash_1 или сделать запрос напрямую к мастер-таблице test.hash. 

Давайте создадим 200 000 строк, и вставим их в основную хаб-таблицу: 

```postgresql
INSERT INTO test.hash (SELECT generate_series(0, 200000));
```

Посмотрим, сколько теперь строк в нашей таблице:

```postgresql
SELECT count(*) FROM test.hash;
```

Результат — 200 000. Но если я дополню запрос ключевым словом ONLY,

```postgresql
SELECT count(*) FROM ONLY test.hash;
```

то у меня возвратится 0. Основная hash-таблица не содержит никаких строк. Она является «слоем», который перенаправляет данные в партиции на основании правила распределения.

Посмотрим, сколько данных у нас лежит в каждой партиции:

```postgresql
SELECT count(*), 'hash 1' AS "Name" FROM test.hash_1
UNION
SELECT count(*), 'hash 2' AS "Name" FROM test.hash_2
UNION
…
SELECT count(*), 'hash 9' AS "Name" FROM test.hash_9
UNION
SELECT count(*), 'hash 10' AS "Name" FROM test.hash_10
```

Общее количество в 200 000 строк разделено +/- равномерно. Партицирование по хеш-функции как раз помогает достичь равномерной нагрузки на каждую из партиций: 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/0be/339/2ef/0be3392ef380d6e88f748f30cf69c235.png)

## Inherited tables — наследуемые таблицы

Смысл наследуемой таблицы напрямую отражён в её названии. Например, у нас есть две таблицы: с обычными городами и со столицами. Столицы задаются тремя атрибутами: название, население и регион:

```postgresql
CREATE TABLE capitals (
  name         VARCHAR,
  population INTEGER,
  state          CHAR(2)
);
```

А обычные города задаются просто названием и количеством населения:

```postgresql
CREATE TABLE cities (
  name         VARCHAR,
  population INTEGER
);
```

Можно переделать данную модель в наследуемом стиле. Мы оставим таблицу «Города» без изменений и создадим обновлённую таблицу «Столицы». В «Столицах» сошлёмся на «Города», дополнив атрибут STATE: 

```postgresql
CREATE TABLE capitals (
  state         CHAR(2)
) INHERITS (cities);
```

Атрибуты, которые находятся в оригинальной таблице «Города», будут наследоваться на уровень зависимой таблицы «Столицы». 

Посмотрим на `INSERT`. Например, вставим в обычные города Казань:

```postgresql
INSERT INTO cities 
VALUES('Kazan', 1000000);
```

и Москву, расширяя её дополнительным атрибутом “MS”:

```postgresql
INSERT INTO cities 
VALUES('Moscow', 8000000, 'MS');
```

Если я теперь обращаюсь к обычным городам, используя `SELECT * FROM cities;`, то в таблице будут представлены обе записи — Казань и Москва. Но если я дополню запрос словом `ONLY`, то мы увидим, что на самом деле в этой таблице хранится только одна строка — Казань. Вторая строка с Москвой находится в «Столицах», отдельной таблице, которая дополнена новым атрибутом. 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/0de/a2a/b36/0dea2ab360261f2bd62ebbb43cb317b8.png)

Другой пример с распределением данных, используя наследуемые таблицы. Я создаю таблицу users и передаю все свойства этой таблицы для десяти наследуемых таблиц:

```postgresql
CREATE TABLE test.users (
  id               INTEGER,
  name         VARCHAR
);
CREATE INDEX idx_users ON test.users (id);

CREATE TABLE users_1 ( ) INHERITS (test.users);
CREATE TABLE users_2 ( ) INHERITS (test.users);
CREATE TABLE users_3 ( LIKE test.users INCLUDING ALL ) 
                                            INHERITS (test.users);
…
CREATE TABLE users_8 ( ) INHERITS (test.users);
CREATE TABLE users_9 ( ) INHERITS (test.users);
CREATE TABLE users_10 ( ) INHERITS (test.users);
```

У меня везде один код, кроме таблицы users_3. Для неё я написал, что нужно создать такую же таблицу, как users, но с указанием `INCLUDING ALL`. Эта очень полезная опция, если вы не хотите повторять атрибуты, комментарии, индексы и check constraints, которые у вас имеются на уровне таблички users. Остальные таблицы тоже созданы будут от аналога users, но индекс, например, наследовать не будут. 

Получается следующая топология. В центре — таблица users, всё зелёное вокруг неё — это наследуемые таблицы. И только users_3 имеет наш индекс: 

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/dae/31e/990/dae31e990bf073bb09737b9a4cbd7e7d.png)

Если вы сделаете запрос: 

```postgresql
SELECT * 
   FROM test.users 
WHERE id = 1;
```

то в случае, если вы не до конца настроили и оптимизировали вашу топологию хранения, у вас, по сути, получится 11 последовательных сканирований наследуемых таблиц. Последовательное сканирование начнётся с мастер-таблицы users, а затем по всем подлежащим таблицам до тех пор, пока не найдётся id = 1. 

Хранение данных без оптимизации запросов — это просто обидно. Возникает вопрос:  зачем мы создали всё это? 

Но выход есть! Мы можем для каждой таблицы определить соответствующий диапазон хранения данных через check constraint:

```postgresql
ALTER TABLE test.users_1 ADD CONSTRAINT partition_check 
CHECK (id >= 0 and id < 100000);

ALTER TABLE test.users_2 ADD CONSTRAINT partition_check 
CHECK (id >= 100000 and id < 200000);

…

ALTER TABLE test.users_10 ADD CONSTRAINT partition_check 
CHECK (id >= 900000 and id <= 1000000);
```

И убедиться, что

```postgresql
SHOW constraint_exclusion = on | partition
```

Check constraint задаёт правило игры для сохранения консистентности данных в рамках таблицы. В нашем случае check constraint важен также для указания базе данных диапазона хранения идентификаторов в конкретных зависимых таблицах. 

PostgreSQL понимает, что существующее правило указывает диапазон данных и нет смысла ходить в users_2, users_3, … ,users_10 , так как check constraint явно указывает, что диапазон для id = 1 лежит в таблице users_1. И в поисках нужной строки оптимизатор направится туда.

Но тут надо отметить, что в процессе будут задействованы две таблицы: сканирование будет происходить по оригинальной таблице users и по наследуемой таблице users_1. PostgreSQL предполагает, что users тоже может хранить данные (зависит как вы в триггере укажете `RETURN NULL;`  или `RETURN NEW;`).

Мы можем ещё больше ускорить процесс поиска, создав индекс на users_1. Это возможно потому, что вы можете контролировать каждую конкретную наследуемую таблицу, как и конкретную партицию. Можете проводить изменение структуры, создание и модернизацию  индексов, добавление столбцов и всё, что удовлетворяет принципу «разделяй и властвуй».

### Распределение трафика по наследуемым таблицам

Какие есть инструменты, чтобы распределять данные между подчинёнными таблицами? В партицированных таблицах это всё работает из коробки, но наследуемые таблицы нужно научить это делать.  

Доступные подходы, для работы которых придётся немного повозиться:

1.  Триггеры, которые определяются на таблицу (вернее триггер + триггерная функция). 
    
2.  Расширение pg_partman.
    
3.  Объекты Database Rules (CREATE DATABASE RULE …).
4. 

# Индексы
Индекс представляет из себя отдельную таблицу с отсортированными значениями и ссылками на запись в основной таблице. Сам индекс можно представить как дерево.
![[Pasted image 20221202122239.png]]


*PostgresSQL предоставляет шесть типов индекстов:* 
* B-дерево
* хеш
* обобщенный инвертированный индекс (GIN)
* обобщенное дерево поиска (GiST)
* индекс блочных диапазонов (BLock Range Index - BRIN).
Индексы разных типов предназначены для решения разных задач. Например, B-дерево эффективно для сравнения на равенство и проверки попадания в диапазон. GIN. GIST - индексы используются для полнотекстового поиска и геопространственных данных. PostgreSQL поддерживает частичные, уникальные и многостолбцовые индексы, а также индексы по выражениям и классы операторов;

## Индексы: кластеризованные/некластеризованные
Дерево состоит из узлов и листьев. Указатели на исходную таблицу хранятся в листьях или могут уже содержать в себе все данные, все зависит от вида индексов. Их бывает двух видов: кластеризованный и некластеризованный.

![[Pasted image 20221202122347.png]]
Кластеризованный индекс уже хранит данные в своих листьях. Он находится в отсортированном виде и создается только один на всю таблицу. Обычно на колонку _id_, которая является первичным ключом (_primary key),_ по умолчанию создается кластеризованный индекс.

Некластеризованный индекс хранит в своих листьях ссылки на записи кластеризованного индекса или на записи из кучи, если кластеризованного индекса нет.

Куча (_heap_) это просто неотсортированные данные таблицы.

На самом деле, кластеризованный индекс это не отдельная таблица, а просто отсортированная таблица по выбранной колонке.

## Индексы: уникальные/неуникальные

Такой индекс обеспечивает уникальность значений в индексируемой колонке. Также есть возможность создать составной уникальный индекс.
В этом случае обеспечивается уникальность значений на все колонки, но не на каждую отдельно. Т.е., если вы создадите составной уникальный индекс на поля _first___name_ и _last_name_, то это означает, что повторяющихся _имен +_ _фамилий_ не будет, но разрешается использовать одинаковые либо _имена,_ либо _фамилии_ по отдельности. При создании первичного ключа уникальный индекс создается автоматически.
![[Pasted image 20221202122432.png]]

## Btree Index

B-tree _(Balanced Tree)_ строит индексы используя реализацию сбалансированного дерева. Он может быть использован в условиях сравнения  или проверке в диапазоне.

![Screen Shot 2017-05-30 at 17.05.22.png](https://doberbeatzblog.files.wordpress.com/2017/03/screen-shot-2017-05-30-at-17-05-22.png?w=1008)

Полезен в следующих случаях:

-   операторы сравнения `>`, `<`, `=`, `>=`, `<=`, `BETWEEN` и `IN`;
-   условия пустоты `IS NULL` и `IS NOT NULL`;
-   операторы поиска подстроки `LIKE` и `~`, если искомая строка закреплена в начале шаблона (например `name LIKE 'Lisa%'`);
-   регистронезависимые операторы поиска подстроки `ILIKE` и `~*`. Но только в том случае, если искомая строка начинается с символа, который одинаков и в верхнем и в нижнем регистре (например числа)`.

B-деревья могут также применяться для получения данных, отсортированных по порядку.

## Hash

Hash индексы используются только при условии равенства `name = 'Bart'` и все. При построении hash индекса участвует hash функция, которая принимает значение `'Bart'` и на выходе, вычисляя hash – `200`, распределяет их по секциям. При корреляции объекты внутри секции выстраиваются в цепочку.

![Screen Shot 2017-06-12 at 19.13.19.png](https://doberbeatzblog.files.wordpress.com/2017/03/screen-shot-2017-06-12-at-19-13-19.png?w=1008)

Создается следующее командой:

**CREATE** **INDEX** _name_ **ON** _table_ **USING** hash _(column)__;_

>  Внимание
> 
> Операции с хеш-индексами в настоящее время не проходят через WAL, так что после аварийной остановки базы данных может потребоваться перестроить хеш-индексы командой `REINDEX`. Кроме того, изменения в хеш-индексах после начальной копии не переносятся при потоковой или файловой репликации, так что в последующих запросах они будут давать неправильные ответы. По этим причинам настоятельно рекомендуется не использовать их.

## GiST

GiST _(Generalized Search Tree)_ для построения индексов использует один из нескольких алгоритмов, наиболее подходящих под тип индексируемого поля. Поэтому набор операторов при работе с которыми может быть задействован этот индекс зависит от типа поля. По умолчанию PostgreSQL предоставляет индексы для некоторых типов данных, таких как [геометрические типы](http://www.postgresql.org/docs/9.5/static/datatype-geometric.html), [сетевые адреса](http://www.postgresql.org/docs/9.1/static/datatype-net-types.html), [диапазоны](http://www.postgresql.org/docs/9.2/static/rangetypes.html) и т.д. Так же этот список можно расширить, установив соответствующие модули.

На базе GiST могут быть реализованы B-деревья, R-деревья и многие другие схемы индексации.

Полезен в следующих случаях:

-   типы **box**, **circle** и **polygon** – операторы `&&`, `&>`, `&<`, `&<|`, `>>`, `<<`, `<<|`, `<@`, `@>`, `@`, `|&>`, `|>>`, `~`, `~=`;
-   типы **inet** и **cidr** – операторы `&&`, `>>`, `>>=`, `>`, `>=`, `<>`, `<<`, `<<=`, `<`, `<=`, `=`;
-   тип **point** – операторы `>>`, `>^`, `<<`, `<@`, `<@`, `<@`, `<^`, `~=`;
-   тип **tsquery** – операторы `<@`, `@>`;
-   тип **tsvector** – оператор `@@`;
-   все типы **range** – операторы `&&`, `&>`, `&<`, `>>`, `<<`, `<@`, `-|-`, `=`, `@>`, `@>`.

## SP-GiST

SP-GiST _(__Space-Partitioned_ _GiST)_ поддерживает деревья поиска с разбиением, что облегчает разработку широкого спектра различных несбалансированных структур данных, в том числе деревьев квадрантов, а также k-мерных и префиксных деревьев. Общей характеристикой этих структур является то, что они последовательно разбивают пространство поиска на сегменты, которые не обязательно должны быть равного размера. При этом поиск, хорошо соответствующий правилу разбиения, с таким индексом может быть очень быстрым.

Полезен в следующих случаях:

-   тип **point** – операторы `>>`, `>^`, `<<`, `<@`, `<@`, `<@`, `<^`, `~=`;
-   типы **box** – операторы `&&`, `&>`, `&<`, `&<|`, `>>`, `<<`, `<<|`, `<@`, `@>`, `@`, `|&>`, `|>>`, `~`, `~=`;
-   все типы **range** – операторы `&&`, `&>`, `&<`, `>>`, `<<`, `<@`, `-|-`, `=`, `@>`, `@>`;
-   все типы **text** – операторы `<`, `<=`, `=`, `=>`, `~<=~`, `~<~`, `~>=~`, `~>~`.



## BRIN Block Range Index

В отличие от привычного B-tree (B-дерева), этот индекс намного эффективнее для очень больших таблиц, и в некоторых ситуациях позволяет заменить собой партицирование. BRIN-индекс имеет смысл применять для таблиц, в которых часть данных уже по своей природе как-то отсортирована. Например, это характерно для логов или для истории заказов магазина, которые пишутся последовательно, а потому уже на физическом уровне упорядочены по дате/номеру, и в то же время таблицы с такими данными обычно разрастаются до гигантских размеров.

Под блоковой зоной (Block Range) подразумевается набор страниц, физически расположенных по соседству в таблице. Для каждой такой зоны создается некий идентификатор, отвечающий за «место» этой зоны в таблице. Для лога это может быть дата создания записи. Поиск по такому индексу осуществляется с включением лишних записей, то есть выбираются все записи, входящие в блоковые зоны с идентификаторами, соответствующими запросу, но среди записей в этих зонах могут попадаться такие, которые на следующем этапе надо будет отфильтровать. Размер индекса при этом очень маленький, и он почти не нагружает базу. Размер индекса обратно пропорционален параметру pages_per_range, отвечающему за количество страниц на зону. В то же время, чем меньше размер зоны, тем меньше «лишних» данных попадёт в результат поиска. В общем, надо подходить к этому параметру с умом.

Индексы BRIN могут иметь один из нескольких встроенных классов операторов, по которым будет осуществляться разбивка на зоны и присвоение идентификаторов. Например, int8_minmax_ops применяется для операций сравнения целых чисел, а date_minmax_ops для сравнения дат. Полная таблица есть в официальной документации.

BRIN _(Block Range Index)_ предназначается для обработки очень больших таблиц, в которых определённые столбцы некоторым естественным образом коррелируют с их физическим расположением в таблице. _Зоной блоков_ называется группа страниц, физически расположенных в таблице рядом; для каждой зоны в индексе сохраняется некоторая сводная информация. Например, в таблице заказов магазина может содержаться поле с датой добавления заказа, и практически всегда записи более ранних заказов и в таблице будут размещены ближе к началу; в таблице, содержащей столбец с почтовым индексом, также естественным образом могут группироваться записи по городам.

Полезен в следующих случаях:

-   типы **box** – операторы `&&`, `&>`, `&<`, `&<|`, `>>`, `<<`, `<<|`, `<@`, `@>`, `@`, `|&>`, `|>>`, `~`, `~=`;
-   все типы **range** – операторы `&&`, `&>`, `&<`, `>>`, `<<`, `<@`, `-|-`, `=`, `@>`, `@>`;
-   операторы сравнения `>`, `<`, `=`, `>=`, `<=`.

## GIN Generalized Inverted Index

Полнотекстовые индексы это есть GIN;

**GIN** (Generalized INverted index) — реализация обратного индекса, используемая в [СУБД](https://ru.wikipedia.org/wiki/%D0%A1%D0%A3%D0%91%D0%94 "СУБД") [PostgreSQL](https://ru.wikipedia.org/wiki/PostgreSQL "PostgreSQL"), в частности, для полнотекстового поиска и поиска по содержимому полей типа [JSON](https://ru.wikipedia.org/wiki/JSON "JSON"). В структуре индексов GIN с каждой лексемой сопоставляется отсортированный (хранящийся в форме [B-дерева](https://ru.wikipedia.org/wiki/B-%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE "B-дерево")) список идентификаторов документов, в которых она встречается.

GIN _(Generalized Inverted Index)_ индексы применимы к составным типам, работа с которыми осуществляется с помощью ключей. Это массивы, jsonb и tsvector. Как и GiST индексы, они могут реализовать один из нескольких алгоритмов. И стандартный набор можно так же расширить, установив модели.

Полезен в следующих случаях:

-   **массивы** – операторы `&&`, `<@`, `=`, `@>`;
-   тип **jsonb** – операторы `?`, `?&`, `?|`, `@>`;
-   тип **tsvector** – операторы `@@` и `@@@`.

Так же GIN индекс может быть создан только для определенных полей jsonb поля.

Поиск по такой структуре намного эффективнее, чем при использовании [GiST](https://ru.wikipedia.org/wiki/GiST "GiST"), однако процесс добавления нового документа медленнее, т.к. изменения вносятся в большое количество записей индекса.
  
GIN был придуман и реализован [Олегом Бартуновым](https://ru.wikipedia.org/wiki/%D0%91%D0%B0%D1%80%D1%82%D1%83%D0%BD%D0%BE%D0%B2,_%D0%9E%D0%BB%D0%B5%D0%B3_%D0%A1%D0%B5%D1%80%D0%B3%D0%B5%D0%B5%D0%B2%D0%B8%D1%87 "Бартунов, Олег Сергеевич") и [Фёдором Сигаевым](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%B3%D0%B0%D0%B5%D0%B2,_%D0%A4%D1%91%D0%B4%D0%BE%D1%80_%D0%93%D0%B5%D0%BD%D0%BD%D0%B0%D0%B4%D1%8C%D0%B5%D0%B2%D0%B8%D1%87 "Сигаев, Фёдор Геннадьевич") в 2005-2006 гг.
![[Pasted image 20221202121542.png]]
## **XML-индекс, JSON-индекс**

Postgres поддерживает только:

-   Полнотекстовый поиск
    
-   Функциональные индексы для выражений XPath
    

Ни один из них не предлагает функциональные возможности, необходимые для извлечения данных на основе значений различных частей XML-документа. Предполагается, что запросы к XML-документу должны быть указаны с использованием языка запросов, такого как XPath или XQuery. Использование функционального индекса для выражения XPath является самым близким способом, однако он не является надежным, и вы можете эффективно запрашивать документ, только используя постоянное выражение XPath, указанное во время создания индекса. Пользователям может потребоваться запросить документ с различными XML-запросами в одном и том же столбце.

## **JSONB**

Существуют два типа данных JSON: `json` и `jsonb`. Они принимают на вход **_почти_** одинаковые наборы значений, а отличаются главным образом с точки зрения эффективности. Тип `json` сохраняет точную копию введённого текста, которую функции обработки должны разбирать заново при каждом выполнении запроса, тогда как данные `jsonb` сохраняются в разобранном двоичном формате, что несколько замедляет ввод из-за преобразования, но значительно ускоряет обработку, не требуя многократного разбора текста. Кроме того, `jsonb` поддерживает индексацию, что тоже может быть очень полезно.

## Фильтрованный  индекс

Это просто индекс с предложением WHERE. Он представляет собой оптимизированный некластеризованный индекс, который может быть сужен для того, чтобы лучше соответствовать подмножеству данных. Например, диапазонам дат, лет, не-NULL значениям или конкретным типам продукции.
**Преимущества**

Использование фильтрованных индексов может улучшить производительность запросов и качество плана по сравнению с полными табличными индексами. Статистика является более точной, поскольку она относится только к строкам фильтрованного индекса, что приводит к лучшим планам выполнения. Также сокращаются накладные расходы на обслуживание индекса благодаря его уменьшенному размеру, и вы обслуживаете только те данные в индексе, которые изменились, а не изменение всей таблицы данных. Наконец, поскольку размер такого индекса меньше, он занимает меньше места на диске.

## **Сканирование только индекса и покрывающий индекс**

Все индексы в PostgreSQL являются _вторичными_, что значит, что каждый индекс хранится вне области основных данных таблицы (которая в терминологии PostgreSQL называется _кучей_ таблицы). Это значит, что при обычном сканировании индекса для извлечения каждой строки необходимо прочитать данные и из индекса, и из кучи. Более того, тогда как элементы индекса, соответствующие заданному условию `WHERE`, обычно находятся в индексе рядом, строки таблицы могут располагаться в куче произвольным образом. Таким образом, обращение к куче при поиске по индексу влечёт множество операций произвольного чтения кучи, которые могут обойтись недёшево, особенно на традиционных вращающихся носителях. (Как описано в [Разделе 11.5](https://postgrespro.ru/docs/postgresql/11/indexes-bitmap-scans "11.5. Объединение нескольких индексов"), сканирование по битовой карте пытается снизить стоимость этих операций, упорядочивая доступ к куче, но не более того.)
Чтобы решить эту проблему с производительностью, PostgreSQL поддерживает _сканирование только индекса_, при котором результат запроса может быть получен из самого индекса, без обращения к куче. Основная идея такого сканирования в том, чтобы выдавать значения непосредственно из элемента индекса, и не обращаться к соответствующей записи в куче. Для применения этого метода есть два фундаментальных ограничения:

1.  Тип индекса должен поддерживать сканирование только индекса. Индексы-B-деревья поддерживают его всегда. Индексы GiST и SP-GiST могут поддерживать его с одними классами операторов и не поддерживать с другими. Другие индексы такое сканирование не поддерживают. Суть нижележащего требования в том, что индекс должен физически хранить или каким-то образом восстанавливать исходное значение данных для каждого элемента индекса. В качестве контрпримера, индексы GIN неспособны поддерживать сканирование только индекса, так как в элементах индекса обычно хранится только часть исходного значения данных.
    
2.  Запрос должен обращаться только к столбцам, сохранённым в индексе. Например, если в таблице построен индекс по столбцам `x` и `y`, и в ней есть также столбец `z`, такие запросы будут использовать сканирование только индекса:
    А эти запросы не будут:    
    (Индексы по выражениям и частичные индексы усложняют это правило, как описано ниже.)

Если два этих фундаментальных ограничения выполняются, то все данные, требуемые для выполнения запроса, содержатся в индексе, так что сканирование только по индексу физически возможно. Но в PostgreSQL существует и ещё одно требование для сканирования таблицы: необходимо убедиться, что все возвращаемые строки «видны» в снимке MVCC запроса, как описано в [Главе 13](https://postgrespro.ru/docs/postgresql/11/mvcc "Глава 13. Управление конкурентным доступом"). Информация о видимости хранится не в элементах индекса, а только в куче; поэтому на первый взгляд может показаться, что для получения данных каждой строки всё равно необходимо обращаться к куче. И это в самом деле так, если в таблице недавно произошли изменения. Однако для редко меняющихся данных есть возможность обойти эту проблему. PostgreSQL отслеживает для каждой страницы в куче таблицы, являются ли все строки в этой странице достаточно старыми, чтобы их видели все текущие и будущие транзакции. Это отражается в битах в _карте видимости_ таблицы. Процедура сканирования только индекса, найдя потенциально подходящую запись в индексе, проверяет бит в карте видимости для соответствующей страницы в куче. Если он установлен, значит эта строка видна, и данные могут быть возвращены сразу. В противном случае придётся посетить запись строки в куче и проверить, видима ли она, так что никакого выигрыша по сравнению с обычным сканированием индекса не будет. И даже в благоприятном случае обращение к кучи не исключается совсем, а заменяется обращением к карте видимости; но так как карта видимости на четыре порядка меньше соответствующей ей области кучи, для работы с ней требуется много меньше операций физического ввода/вывода. В большинстве ситуаций карта видимости просто всё время находится в памяти.
Таким образом, тогда как сканирование только по индексу возможно лишь при выполнении двух фундаментальных требований, оно даст выигрыш, только если для значительной части страниц в куче таблицы установлены биты полной видимости. Но таблицы, в которых меняется лишь небольшая часть строк, встречаются достаточно часто, чтобы этот тип сканирования был весьма полезен на практике.
Чтобы эффективно использовать возможность сканирования только индекса, вы можете создавать _покрывающие индексы_. Такие индексы специально предназначены для включения столбцов, которые требуются в определённых часто выполняемых запросах. Так как в запросах обычно нужно получить не только столбцы, по которым выполняется поиск, PostgreSQL позволяет создать индекс, в котором некоторые столбцы будут просто «дополнительной нагрузкой», но не войдут в поисковый ключ. Это реализуется предложением `INCLUDE`, в котором перечисляются дополнительные столбцы. Например, если часто выполняется запрос вида
```postgresql
SELECT y FROM tab WHERE x = 'key';
```

при традиционном подходе его можно ускорить, создав индекс только по `x`. Однако такой индекс:

```postgresql
CREATE INDEX tab_x_y ON tab(x) INCLUDE (y);
```
может удовлетворить такие запросы при сканировании только индекса, так как значение `y` можно получить из индекса, не обращаясь к данным в куче.

Так как столбец `y` не является частью поискового ключа, он не обязательно должен иметь тип данных, воспринимаемый данным индексом; он просто сохраняется внутри индекса и никак не обрабатывается механизмом индекса. Кроме того, в случае с уникальным индексом, например:

```postgresql
CREATE UNIQUE INDEX tab_x_y ON tab(x) INCLUDE (y);
```

условие уникальности распространяется только на столбец `x`, а не на `x` и `y` в совокупности. (Предложение `INCLUDE` можно также добавить в ограничения `UNIQUE` и `PRIMARY KEY`, что позволяет определить такой индекс альтернативным образом.)

Добавлять в индекс неключевые дополнительные столбцы следует обдуманно, особенно когда это большие столбцы. Если размер кортежа в индексе превысит максимально допустимый размер для типа индексов, при добавлении данных возникнет ошибка. В любом случае в неключевых столбцах дублируются данные из самой таблицы, что приводит к разрастанию индекса, а следствием этого может быть замедление запросов. И помните, что практический смысл включать дополнительные столбцы в индекс есть только тогда, когда таблица меняется достаточно медленно, и при сканировании только индекса не приходится обращаться к куче. Если кортеж в любом случае придётся прочитывать из кучи, получить значение столбца из него ничего не стоит. Покрывающие индексы имеют и другие ограничения: в настоящее время в качестве неключевых столбцов нельзя задать выражения, и поддерживаются такие индексы только одного типа — B-деревья.

До появления в PostgreSQL покрывающих индексов (`INCLUDE`) пользователям иногда приходилось задействовать дополнительные столбцы как обычные столбцы индекса, то есть писать

```postgresql
CREATE INDEX tab_x_y ON tab(x, y);
```

даже не намереваясь когда-либо использовать `y` в предложении `WHERE`. Это работает, когда дополнительные столбцы добавляются в конец; делать их начальными неразумно по причинам, описанным в [Разделе 11.3](https://postgrespro.ru/docs/postgresql/11/indexes-multicolumn "11.3. Составные индексы"). Однако этот подход не годится для случая, когда вам нужно обеспечить уникальность ключевого столбца (столбцов). К тому же, если явно добавить пометку `INCLUDE` для не участвующих в поиске столбцов, индекс будет немного меньше, так как такие столбцы не хранятся на верхних уровнях B-дерева.

В принципе сканирование только индекса может применяться и с индексами по выражениям. Например, при наличии индекса по `f(x)`, где `x` — столбец таблицы, должно быть возможно выполнить
```postgresql
SELECT f(x) FROM tab WHERE f(x) < 1;
```


как сканирование только индекса; и это очень заманчиво, если `f()` — сложная для вычисления функция. Однако планировщик PostgreSQL в настоящее время может вести себя не очень разумно. Он считает, что запрос может выполняться со сканированием только индекса, лишь когда из индекса могут быть получены все **_столбцы_**, требующиеся для запроса. В этом примере `x` фигурирует только в контексте `f(x)`, но планировщик не замечает этого и решает, что сканирование только по индексу невозможно. Если сканирование только индекса заслуживает того, эту проблему можно обойти, добавив `x` как неключевой столбец, например:
```postgresql
CREATE INDEX tab_f_x ON tab (f(x)) INCLUDE (x);
```

Если это делается ради предотвращения многократных вычислений `f(x)`, следует также учесть, что планировщик не обязательно свяжет упоминания `f(x)`, фигурирующие вне индексируемых предложений `WHERE`, со столбцом индекса. Обычно он делает это правильно в простых запросах, вроде показанного выше, но не в запросах с соединениями. Эти недостатки могут быть устранены в будущих версиях PostgreSQL.

С использованием частичных индексов при сканировании только по индексу тоже связаны интересные особенности. Предположим, что у нас есть частичный индекс, показанный в [Примере 11.3](https://postgrespro.ru/docs/postgresql/11/indexes-partial#INDEXES-PARTIAL-EX3 "Пример 11.3. Настройка частичного уникального индекса"):
```postgresql
CREATE UNIQUE INDEX tests_success_constraint ON tests (subject, target)
WHERE success;

```


В принципе с ним мы можем произвести сканирование только по индексу при выполнении запроса
```postgresql
SELECT target FROM tests WHERE subject = 'some-subject' AND success;
```


Но есть одна проблема: предложение `WHERE` обращается к столбцу `success`, который отсутствует в результирующих столбцах индекса. Тем не менее сканирование только индекса возможно, так как плану не нужно перепроверять эту часть предложения `WHERE` во время выполнения: у всех записей, найденных в индексе, значение `success = true`, так что в плане его не нужно проверять явно. PostgreSQL версий 9.6 и новее распознает такую ситуацию и сможет произвести сканирование только по индексу, но старые версии неспособны на это.
  

**Дополнительные поля индексов**

**Параметры хранения индекса**

Необязательное предложение WITH определяет _параметры хранения_для индекса. У каждого метода индекса есть свой набор допустимых параметров хранения. Следующий параметр принимают методы B-дерево, хеш, GiST и SP-GiST:
**fillfactor**
Фактор заполнения для индекса определяет в процентном отношении, насколько плотно метод индекса будет заполнять страницы индекса. Для B-деревьев концевые страницы заполняются до этого процента при начальном построении индекса и позже, при расширении индекса вправо (добавлении новых наибольших значений ключа). Если страницы впоследствии оказываются заполненными полностью, они будут разделены, что приводит к постепенному снижению эффективности индекса. Для B-деревьев по умолчанию используется фактор заполнения 90, но его можно поменять на любое целое значение от 10 до 100. Фактор заполнения, равный 100, полезен для статических таблиц и помогает уменьшить физический размер таблицы, но для интенсивно изменяемых таблиц лучше использовать меньшее значение, чтобы разделять страницы приходилось реже. С другими методами индекса фактор заполнения действует по-другому, но примерно в том же ключе; значение фактора заполнения по умолчанию для разных методов разное.
Индексы GiST дополнительно принимают этот параметр:
**buffering**
Определяет, будет ли при построении индекса использоваться буферизация/

Индексы GIN принимают другие параметры:
**fastupdate**

Этот параметр управляет механизмом быстрого обновления, описанным в [Подразделе 63.4.1](https://postgrespro.ru/docs/postgresql/9.6/gin-implementation#gin-fast-update "63.4.1. Методика быстрого обновления GIN"). Он имеет логическое значение: ONвключает быстрое обновление, OFFотключает его. (Другие возможные написания ONи OFFперечислены в [Разделе 19.1](https://postgrespro.ru/docs/postgresql/9.6/config-setting "19.1. Изменение параметров").) Значение по умолчанию — ON.

**Примечание**
Выключение fastupdateв ALTER INDEXпредотвращает помещение добавляемых в дальнейшем строк в список записей, ожидающих индексации, но записи, добавленные в этот список ранее, в нём остаются. Чтобы очистить очередь операций, надо затем выполнить VACUUMдля этой таблицы или вызвать функцию gin_clean_pending_list.
**gin_pending_list_limit**

Пользовательский параметр [gin_pending_list_limit](https://postgrespro.ru/docs/postgresql/9.6/runtime-config-client#guc-gin-pending-list-limit). Его значение задаётся в килобайтах.

Индексы BRINпринимают другой параметр:
**pages_per_range**

Определяет, сколько блоков таблицы образуют зону блоков для каждой записи в индексе BRIN(за подробностями обратитесь к [Разделу 64.1](https://postgrespro.ru/docs/postgresql/9.6/brin-intro "64.1. Введение")). Значение по умолчанию — 128.


## Литература

1. https://habr.com/ru/company/quadcode/blog/671254/
2. Салахалдин Джуба, Андрей Волков Изучаем PostgreSQL 10, Second Edition 2019;

[[../../../Python/Архитектура/Хранение данных]] [[7 типов современных баз данных предназначение, достоинства и недостатки]]