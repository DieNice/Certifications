---
tags:
  - Аттестация
  - Postgres
  - Usefull
author: Проскурин Д.А
date: 2024-04-04
---

## Подготовка тестовой базы данных[^4]

1. Предварительно нужно будет установить Docker
2. Скачать демонстрационую базу по [ссылке](https://postgrespro.ru/docs/postgrespro/10/demodb-bookings-installation)
3. Создать папку с файлом Dockerfile.txt, скопировать/вставить код ниже, в папку с Dockerfile.txt скопировать sql-бэкап.

```Dockerfile
FROM postgres:15.1-alpine

LABEL author="Test Name"
LABEL description="Postgres Image for demo"
LABEL version="1.0"

COPY *.sql /docker-entrypoint-initdb.d/
EXPOSE 5432 5432
```
4. Запустить команды
`docker build . -f Dockerfile.txt -t test_postgres`
`docker run --rm -i -p 5432:5432 -e POSTGRES_PASSWORD=password test_postgres`

Ниже представлена общая схема базы данных [^5]:
![](../images/Pasted%20image%2020240404215046.png)


## Общие подходы к оптимизации

- **Общие методы**
	- Настройка параметров
		- Настройка под имеющуюся нагрузку
		- Глобальное влияние на всю систему
		- Мониторинг
	- Оптимизация запросов
		- Уменьшение нагрузки
		- Запрос или несколько запросов
		- Профилирование

## Этапы обработки запроса

### Разбор
Текст запроса разбирается в синтаксическое дерево запроса.
Над синтаксическим деревом выполняется семантический анализ (определяются затрагиваемые сущности, проверяется доступ).

**Пример запроса:**
![](Pasted%20image%2020240408230820.png)
**RTE (Range Table Entry)** - таблицы, подзапросы, результаты соединений и другие наборы строк.

На этапе семантического анализа анализатор связывается с системным каталогом производит связывание сущностей, проверяет права.

### Переписывание (трансформация)
![](Pasted%20image%2020240408231307.png)
После семантического анализа выполняется переписывание запроса по определенным правилам, как следствие формируется новое дерево запроса.

**Пример**: Вместо представления подставляется текст запроса.
![](Pasted%20image%2020240408231348.png)
### Планирование (оптимизация)
![](Pasted%20image%2020240408231505.png)
Планировщик (оптимизатор) может выполнить запрос разными способами (т.к. SQL-декларативный язык), поэтому он перебирает их, оценивает и выбирает наиболее эффективный способ.

>[!important] Оценка делается на основе некоторой математической модели исходя из информации об обрабатываемых данных (статистики).

Тот способ для которого прогнозируется минимальная стоимость, представляется в виде дерева плана.

>[!important] План запроса
>План запроса можно посмотреть выполнив команду EXPLAIN <запрос>

rows - число строк
стоимость - cost


### Выполнение

![](Pasted%20image%2020240408232015.png)
В-четвертых, запрос выполняется (execute) в соответствии с выбранным планом, и результат возвращается клиенту

![](Pasted%20image%2020240408232351.png)

На этапе выполнения запрос (дерево плана) выполняется как конвейер.
Выполнение начинается с корня дерева, идет обращение к нижележащим узлам, те в свою очередь к своим потомкам, те отдают результат наверх и получив данные родительский узел возвращает результат наверх.

>[!info] NESTLOOP
>Некоторые узлы соединяют данные полученные от нескольких источников. Узел обращается по очереди к двум дочерним узлам , соединяется их попарно и получив строки возвращает наверх, узлу соединения.



>[!info] SORT 
>Некоторые узлы могут вернуть результат, только получив от нижестоящих узлов все данные.

>[!info] SEQSCAN
>Другие узлы могут возвращать данные по мере поступления , например доступ к данным при помощи чтения может отдавать результат наверх по мере чтения


## Простой протокол и этапы обработки запросов

Самый простой протокол применяется когда на сервер отправляется оператор или запрос select, или запрос с returning.
![](Pasted%20image%2020240409234135.png)

>[!important] EXPLAIN ANALYZE
>Обычный удобный способ узнать время выполнения и время планирования — команда EXPLAIN ANALYZE


>[!example] 
>```sql
>explain analyze SELECT model FROM aircrafts WHERE aircraft_code = '773';
>
>Seq Scan on aircrafts_data ml  (cost=0.00..1.36 rows=1 width=32) (actual time=0.035..0.036 rows=1 loops=1)
  Filter: (aircraft_code = '773'::bpchar)
  Rows Removed by Filter: 8
Planning Time: 0.048 ms
Execution Time: 0.048 ms
>```
> 

>[!advice] Обозначения EXPLAIN
>- cost — оценка стоимости;
>- rows — оценка числа строк, возвращаемых операцией;
>- width — оценка размера одной записи в байтах.

### JIT-компиляция 

>[!tip] JIT - just in time
>Используется для компиляции части интерпретируемого кода в исходный код с целью оптимизации.

JIT-компиляции выгодна при выполнении "грузных" OLAP-запросов, для коротких OLTP-запросов накладные расходы могут превышать выгоду. По умолчанию JIT-компиляция включена.


## Расширенный протокол
Расширенный протокол запросов означает возможность использования подготовленных операторов и курсоров.
![](Pasted%20image%2020240410215307.png)

Запрос может быть подготовлен. Это означает что когда клиент первый раз передает запрос серверу, выполняет разбор в синтаксическое дерево, переписывает и сохраняет в локальную память.
Чтобы выполнить подготовленный запрос пользователь называет имя запроса и передает параметры для выполнения запроса.
За счет подготовки удается избежать повторного разбора и переписывания одного и того же запроса, если он выполняется в одном сеансе неоднократно.

Во-вторых, можно использовать курсоры. Механизм курсоров позволяет получать результат выполнения запроса не весь сразу, а построчно.
Информация об открытом курсоре также хранится в локальной памяти обслуживающего процесса.

Если sql-запрос не имеет параметру, то серверу нет смысла перепланировать запрос. Это позволяет получить результат ещё быстрее и экономить ресурсы.

>[!info] SQL-инъекции
>Ещё один несомненный плюс от использования подготовленных операторов это гарантия безопасности от внедрения sql-кода.

>[!example] Пример подготовленного запроса
>```sql
PREPARE prepare_model (varchar) as
SELECT model FROM aircrafts WHERE aircraft_code = $1;
execute prepare_model('763');

>[!tip] Все подготовленные запросы можно смотреть `SELECT * FROM pg_prepared_statements`

Если подготовленный оператор больше не нужен, его можно удалить командой **DEALLOCATE**, но в любом случае оператор пропадет при завершении сеанса.

## Подробнее о планировании

**Статистика** содержит данные о размере таблиц и распределении данных.
**Оценка координальности**(для расчёта требуется статистика): 
	- доля выбираемых строк;
	- итоговое число строк;
**Оценка стоимости** впервую очередь зависит от типа узла и числа обрабатываемых строк.
**Перебор планов запросов** - выбирается план с наименьшей стоимостью.

Стоимость каждого узла синтаксического дерева разбора зависит от типа этого узла. К примеру, стоимость обычного чтения будет выше, чем стоимость чтения данных при помощи индекса.

>[!important] Основные понятия оценки объема данных
>**Кардинальность** - общее число строк;
>**Селективность** - доля строк отбираемых условием (предикатами);
>

Для оценки кардинальности и селективности необходимо знать размер таблиц и распределенных данных по столбцам. Всё в итоге сводится к статистике, информации которая обновляется и собирается при использовании команды `ANALYZE`.

**Основные ошибки оптимизатора:**
- Неправильная оценка кардинальности;
- Неточность/несовершенство моделей оценки;
- Неадекватная статистика;

>[!warning] Оценка кардинальности является рекурсивной процедурой

## Оценка стоимости
![](Pasted%20image%2020240410223606.png)
Процесс оценки стоимости выполнения запроса является рекурсивным.
Процесс оценки стоимости выполняется на основе математической модели заложенной в планировщик, с учетом числа обрабатываемых строк.

Стоимость состоит из двух частей: начальная стоимость..стоимость получения всех строк выборки.
В большинстве случаев начальная стоимость равна нуле. Пример когда начальная подготовленная работа не равна нулю - сортировка.

>[!tip] Важно понимать что оценка стоимость отражает оценку планировщика в некоторых условных единицах и служит ориентиром чтобы планировщик мог сравнивать запросы и выбирать лучший.
>

Оптимизатор старается перебирать все возможные планы выполнения запроса. Для сокращения перебора используется алгоритмы из динамического программирования, но при большой количество вариантов часть отсекается (либо генетический алгоритм GEQO) и выбирается план запроса далеко не лучший , не из-за ошибки модели, а из-за того что план просто не был рассмотрен. 
Для обычных запросов лучшим планом считается план с минимальной полной стоимостью.


## Последовательное сканирование[^7]

>[!important] Последовательное сканирование работает эффективно когда происходить чтение всей таблицы или селективность выборки низкая.

Последовательное сканирование происходит через буферный кеш (структура данных буферное кольцо).

### Последовательное сканирование (Seq Scan)

>[!example] Пример последовательного сканирования
```postgresql
EXPLAIN SELECT * FROM flights;
                           QUERY PLAN                           
----------------------------------------------------------------
 Seq Scan on flights  (cost=0.00..4772.67 rows=214867 width=63)
(1 row)
```

### Параллельные планы выполнения

![](Pasted%20image%2020240411221436.png)

Идея простая - ведущий процесс порождает подпроцессы (при помощи postmaster), те выполняют свою параллельную часть , отдают результаты главному процессу.
Если главные процесс не успели загрузить данными, то он тоже присоединяется к обработке.

>[!warning] Отдельные узлы плана выполняются выполняются отдельными процессами.

![](Pasted%20image%2020240411221752.png)
### Параллельное сканирование (Parallel Seq Scan)


>[!example] Хорошим примером параллельного использования является агрегация.

```sql
EXPLAIN SELECT count(*) FROM bookings;

                                         QUERY PLAN                                         
--------------------------------------------------------------------------------------------
 Finalize Aggregate  (cost=25442.58..25442.59 rows=1 width=8)
   ->  Gather  (cost=25442.36..25442.57 rows=2 width=8)
         Workers Planned: 2
         ->  Partial Aggregate  (cost=24442.36..24442.37 rows=1 width=8)
               ->  Parallel Seq Scan on bookings  (cost=0.00..22243.29 rows=879629 width=0)
(5 rows)

```

>[!danger] Иногда узким местом становится обработка данных в ведущем процессоре. По умолчанию ведущий процесс участвует в обработке, его можно отключить, чтобы разгрузить.
>SET parallel_leader_participation = off;


>[!info] max_parallel_workers_per_gather ограничивает число процессов параллельного участка плана и сейчас действует значение по умолчанию (2).
>Для конкретной таблицы параметром хранения parallel_workers можно задать рекомендованное количество процессов:
=> ALTER TABLE bookings SET (parallel_workers = 4);

>[!danger] НЕ РАСПАРАЛЛЕЛИВАЮТСЯ
>1. Запросы на запись (+запросы с блокировкой строк);
>2. Курсоры (+For в Pl/pgsql);
>3. Запросы с функциями parallel unsafe;
>4. Запросы в функциях, вызванных из распараллеленного запроса;

**Только последовательно:**
- Чтение результатов общих табличных выражений (CTE);
- Чтение результатов не раскрываемых подзапросов;
- Обращения к временным таблицам;
- Вызовы функций PARALLEL RESTRICTED;
- Функции, использующие вложенные транзакции;

### Краткий вывод

Последовательное сканирование читает всю таблицу эффективно при низкой селективности.
Параллельное выполнение в ряде случаев позволяет ускорить запрос.

## Индексный доступ[^8]

**Индекс** - вспомогательная структура данных во внешней памяти, сопоставляет ключи и идентификаторы строк таблицы.
**Использование:** Ускорение доступа, поддержка ограничений целостности.

![](Pasted%20image%2020240411223834.png)

>[!example] 
>`EXPLAIN SELECT * FROM bookings WHERE book_ref = 'CDE08B';`
>---
>Index Scan using bookings_pkey on bookings  (cost=0.43..8.45 rows=1 width=21)
>Index Cond: (book_ref = 'CDE08B'::bpchar)


>[!info] Индексный доступ может выполняться в параллельном режиме.
![](Pasted%20image%2020240411231400.png)

**Пример параллельного сканирования индекса:**
```sql
EXPLAIN SELECT sum(total_amount) 
FROM bookings WHERE book_ref < '400000';
                                                    QUERY PLAN                                                    
------------------------------------------------------------------------------------------------------------------
 Finalize Aggregate  (cost=16864.79..16864.80 rows=1 width=32)
   ->  Gather  (cost=16864.57..16864.78 rows=2 width=32)
         Workers Planned: 2
         ->  Partial Aggregate  (cost=15864.57..15864.58 rows=1 width=32)
               ->  Parallel Index Scan using bookings_pkey on bookings  (cost=0.43..15314.81 rows=219906 width=6)
                     Index Cond: (book_ref < '400000'::bpchar)
(6 rows)
```

### Сканирование только индекса

Покрывающий индекс.
Карта видимости.

### Include-индексы

Индекс с дополнительными неключевыми столбцами

CREATE INDEX ... INCLUDE (...)
**Неключевые столбцы:**
- Не используются при поиске по индексу;
- Не учитываются ограничения уникальности;
- Значения хранятся в индексе и возвращаются без обращения к таблице;

### Parallel index only scan

![](Pasted%20image%2020240411232720.png)

### Краткий вывод

Индексы ускоряют доступ при высокой селективности.
Поддерживают ограничения целостности.
Позволяют получить отсортированные данные.
Покрывающие индексы позволяют экономить на обращении к таблице.
Возможен параллельный индексный доступ.



## Сканирование по битовой карте[^9]
Сначала сканируется индекс и в локальной памяти процесса строится битовая карта. Битовая карта состоит из фрагментов. Каждый фрагмент соответствует табличным страницам, а каждый бит фрагмента соответствует версии строки в этой странице.
![](Pasted%20image%2020240411235448.png)

Сканирование по битовой карте может выполняться параллельно.
Неточные фрагменты.

### Краткий вывод

Высокая селективность - индекс;
Средняя селективность - битовая карта;
Низкая селективность - последовательное сканирование;

## Система версионирования схем на проекте

Для реализации системы версионирования схем в проекте на PostgreSQL существует несколько подходов, каждый из которых имеет свои преимущества и недостатки. Вот некоторые из них:
1. **Создание отдельной таблицы для истории изменений**: Этот подход предполагает создание новой таблицы, которая будет хранить историю изменений записей. Таблица будет содержать копию схемы исходной таблицы, а также дополнительные поля для хранения времени изменения и внешнего ключа на исходную таблицу. Этот метод позволяет легко восстанавливать исторические версии записей, но требует дополнительного места для хранения данных [1](https://stackoverflow.com/questions/4185235/ways-to-implement-data-versioning-in-postresql).
2. **Использование схемы без структуры для хранения изменений**: В этом случае создается таблица, которая будет хранить только изменения к записям, без необходимости синхронизации с исходной таблицей. Такая таблица может содержать поля для идентификатора записи, времени изменения, имени поля и его значения. Этот подход уменьшает объем хранимых данных, но может усложнить процесс восстановления полной версии записи [1](https://stackoverflow.com/questions/4185235/ways-to-implement-data-versioning-in-postresql).
3. **Сериализация записей в формате JSON**: Другой вариант — хранение записей или изменений записей в формате JSON. Это позволяет сохранять историю изменений в более гибкой форме, но требует дополнительной обработки данных при восстановлении [1](https://stackoverflow.com/questions/4185235/ways-to-implement-data-versioning-in-postresql).
4. **Использование расширений для версионирования**: Существуют расширения, такие как `temporal_tables`, которые предоставляют функциональность версионирования. Однако, стоит отметить, что они могут не поддерживаться в некоторых управляемых экземплярах PostgreSQL, например, на Azure или AWS [3](https://hypirion.com/musings/implementing-system-versioned-tables-in-postgres).
5. **Git-подобное версионирование**: Этот подход предполагает использование системы контроля версий, такой как Git, для хранения истории изменений схемы. Это может быть полезно для проектов, где часто происходят изменения схемы, но требует дополнительной настройки и может быть избыточным для некоторых приложений [4](https://www.specfy.io/blog/7-git-like-versioning-in-postgres).
6. **Использование инструментов управления схемами**: Существуют специализированные инструменты, такие как Sqitch, Pyrseas, DBSteward, которые помогают в управлении изменениями схемы, включая версионирование. Эти инструменты могут автоматизировать процесс миграции схемы и обеспечивать ее совместимость [5](https://wiki.postgresql.org/wiki/Change_management_tools_and_techniques).
Выбор подхода зависит от конкретных требований проекта, включая частоту изменений схемы, объем хранимых данных и требования к производительности.

В PostgreSQL параметр `SET search_path` используется для управления порядком поиска схем в сессии. Этот порядок определяет, в каких схемах PostgreSQL будет искать объекты (таблицы, функции и т.д.), когда в запросе используется неполное имя объекта. По умолчанию значение `search_path` равно `$user, public`, что означает, что PostgreSQL сначала будет искать объекты в схеме, имя которой совпадает с именем пользователя, а затем в общедоступной схеме [3](https://docs.aws.amazon.com/prescriptive-guidance/latest/tuning-postgresql-parameters/search-path.html).

Изменение параметра `search_path` может улучшить производительность, особенно если у вас много схем или если вам нужно получить доступ к объектам в определенной схеме. Когда вы устанавливаете `search_path` на конкретную схему, PostgreSQL может быстрее найти объекты, не иская их в нескольких схемах [3](https://docs.aws.amazon.com/prescriptive-guidance/latest/tuning-postgresql-parameters/search-path.html).

Параметр `search_path` может быть установлен на разных уровнях:

- На уровне функции: применяется только во время выполнения функции внутри функции.
- На уровне сессии: применяется только в течение жизни сессии.
- На уровне пользователя базы данных: применяется только для новых сессий.
- На уровне пользователя сервера: применяется только для новых сессий.
- На уровне базы данных: применяется только для новых сессий [4](https://www.postgresonline.com/article_pfriendly/279.html).

Пример использования `SET search_path`:
```
SET search_path = ag_catalog, "$user", public;
```

Этот пример устанавливает порядок поиска схем в `ag_catalog`, затем в схеме, имя которой совпадает с именем текущего пользователя, и, наконец, в общедоступной схеме [1](https://stackoverflow.com/questions/76212004/what-is-the-use-of-set-search-path-in-postgresql).

Изменение `search_path` может быть полезно для оптимизации производительности и для управления доступом к объектам в базе данных, особенно в многопользовательских приложениях, где необходимо контролировать, какие таблицы и функции могут быть доступны для различных пользователей [4](https://www.postgresonline.com/article_pfriendly/279.html).


## Безопасность в SQL запросах

### 22.6 Безопасность в SQL запросах
Функции, триггеры и политики защиты на уровне строк позволяют пользователям внедрять код в обслуживающие процессы, который может быть непреднамеренно выполнен другими пользователями. Таким образом эти механизмы позволяют пользователям запускать «троянский код» относительно просто. Лучшая защита от этого — строгое ограничение круга лиц, которые могут создавать объекты. Там где это невозможно, пишите запросы так, чтобы они ссылались только на объекты с доверенными владельцами. Удалите из search_path любые схемы, в которых могут создавать объекты недоверенные пользователи. Функции выполняются внутри серверного процесса с полномочиями пользователя операционной системы, запускающего сервер базы данных. Если используемый для функций язык программирования разрешает неконтролируемый доступ к памяти, то это даёт возможность изменить внутренние структуры данных сервера. Таким образом, помимо всего прочего, такие функции могут обойти ограничения доступа к системе. Языки программирования, допускающие такой доступ, считаются «недоверенными» и создавать функции на этих языках PostgreSQL разрешает только суперпользователям.

### 76.3. Статистика планировщика и безопасность

Доступ к таблице pg_statistic разрешён только суперпользователям, так что обычные пользователи не могут получить из неё сведения о содержимом таблиц других пользователей.

### 34.3.4. Экранирование строковых значений для включения в SQL-команды

Безопасность в SQL запросах является критически важной для защиты данных и предотвращения несанкционированного доступа. Вот несколько ключевых практик и рекомендаций для обеспечения безопасности SQL запросов:

1. **Использование параметризованных запросов**: Этот метод предотвращает SQL инъекции, позволяя разработчикам безопасно передавать параметры в SQL запросы. Параметризованные запросы автоматически обрабатывают входные данные, предотвращая выполнение вредоносного кода [2](https://www.sqlservercentral.com/articles/a-few-best-practices-for-strong-sql-server-security).
2. **Валидация и санитизация входных данных**: Проверка входных данных на наличие вредоносного кода и его очистка от потенциально опасных символов является важным шагом в предотвращении SQL инъекций. Это включает в себя отказ от использования определенных символов, таких как `;`, `'`, `--`, `/* ... */`, и `xp_` [1](https://learn.microsoft.com/en-us/sql/relational-databases/security/sql-server-security-best-practices?view=sql-server-ver16).
3. **Использование Always Encrypted**: Для защиты чувствительных данных, таких как личная информация, Always Encrypted позволяет шифровать данные на уровне столбцов, обеспечивая их безопасность как в покое, так и при передаче данных. Этот метод требует минимальных изменений в коде приложения и обеспечивает высокй уровень защиты [1](https://learn.microsoft.com/en-us/sql/relational-databases/security/sql-server-security-best-practices?view=sql-server-ver16).
4. **Динамическое маскирование данных (Dynamic Data Masking, DDM)**: Когда использование Always Encrypted невозможно, DDM может быть использовано для обфускации данных на уровне столбца, что также помогает защитить чувствительную информацию [1](https://learn.microsoft.com/en-us/sql/relational-databases/security/sql-server-security-best-practices?view=sql-server-ver16).
5. **Предоставление разрешений на уровне столбцов**: Вы можете ограничить доступ к определенным столбцам таблицы, предоставляя разрешения только на операции SELECT, REFERENCES и UPDATE на уровне столбца. Это позволяет контролировать, какие данные могут быть просмотрены или изменены пользователями [1](https://learn.microsoft.com/en-us/sql/relational-databases/security/sql-server-security-best-practices?view=sql-server-ver16).
6. **Блокировка SQL инъекций**: Предотвращение SQL инъекций является ключевым аспектом защиты веб-приложений. Основные методы защиты включают использование параметризованных запросов и валидацию входных данных [2](https://www.sqlservercentral.com/articles/a-few-best-practices-for-strong-sql-server-security).
7. **Использование строгих методов аутентификации и авторизации**: Убедитесь, что только авторизованные пользователи могут получить доступ к базе данных. Применяйте сильные пароли и хеширование для защиты учетных данных [2](https://www.sqlservercentral.com/articles/a-few-best-practices-for-strong-sql-server-security).
8. **Реализация шифрования данных**: Используйте TDE (Transparent Data Encryption) для шифрования данных на диске и SSL/TLS для защиты данных в процессе передачи, чтобы предотвратить несанкционированный доступ [2](https://www.sqlservercentral.com/articles/a-few-best-practices-for-strong-sql-server-security).
9. **Аудит и логирование**: Регулярно проверяйте логи активности и интегрируйте их с системами SIEM для обеспечения безопасности и контроля за действиями в базе данных [2](https://www.sqlservercentral.com/articles/a-few-best-practices-for-strong-sql-server-security).
10. **Мониторинг производительности**: Поддерживайте эффективность и безопасность базы данных, мониторя ее производительность и соответствие нормативным требованиям [2](https://www.sqlservercentral.com/articles/a-few-best-practices-for-strong-sql-server-security).

Следуя этим рекомендациям, вы сможете значительно улучшить безопасность ваших SQL запросов и защитить вашу базу данных от различных угроз.

## Оконные функции

Использование индексов в оконных функциях PostgreSQL может улучшить производительность запросов. Для этого нужно указывать в запросе индексированные столбцы.
Например, если сортировка строк осуществляется по индексированному столбцу, то запрос выполнится быстрее.
**Важно помнить, что оконные функции разрешается использовать в запросе только в списке SELECT и предложении ORDER BY**. Во всех остальных предложениях, включая GROUP BY, HAVING и WHERE, они запрещены.

```postgresql
CREATE INDEX idx_orders_date ON orders (order_date);

SELECT
    order_id,
    order_date,
    SUM(order_amount) OVER (ORDER BY order_date) as running_total
FROM orders;
```

В этом примере, если `order_date` имеет индекс, PostgreSQL может использовать этот индекс для эффективного определения порядка строк для оконной функции `SUM`, что ускоряет выполнение запроса.

**Рекомендации по индексам при использовании оконных функций:**
При использовании оконных функций в SQL, особенно при работе с большими объемами данных, важно учитывать следующие рекомендации для оптимизации производительности и эффективности запросов:

1. **Использование индексов**: Хотя оконные функции не напрямую влияют на использование индексов, порядок и условия, указанные в `ORDER BY` и `PARTITION BY`, могут значительно повлиять на производительность запроса. Убедитесь, что используемые для сортировки и разделения данных поля имеют индексы, чтобы ускорить обработку запросов.
2. **Оптимизация условий разделения**: При использовании `PARTITION BY`, выбирайте поля, которые имеют высокую кардинальность (много уникальных значений), чтобы уменьшить количество групп, которые нужно обрабатывать. Это может существенно улучшить производительность запросов.
3. **Ограничение количества возвращаемых строк**: Если ваш запрос возвращает большое количество строк, рассмотрите возможность использования `LIMIT` или `FETCH` для ограничения результатов. Это может помочь уменьшить нагрузку на систему и ускорить обработку запроса.
4. **Использование ранжирующих функций эффективно**: Функции `ROW_NUMBER()`, `RANK()`, `DENSE_RANK()`, и `NTILE()` могут быть полезны для различных аналитических задач, но их использование требует внимательного подхода к оптимизации. Например, `RANK()` и `DENSE_RANK()` могут быть более ресурсоемкими, чем `ROW_NUMBER()`, если вам не нужно учитывать равенство значений.
5. **Анализ и тестирование**: Регулярно проводите анализ производительности ваших запросов с использованием оконных функций. Используйте инструменты мониторинга и профилирования запросов, чтобы определить узкие места и оптимизировать запросы соответственно.
6. **Обучение и практика**: Постоянно углубляйте свои знания в области оконных функций и их применения. Практика и эксперименты помогут вам лучше понять, как эти функции влияют на производительность и как их можно оптимизировать для конкретных задач.

Важно помнить, что эффективность использования оконных функций во многом зависит от конкретной структуры данных, схемы базы данных и специфики запросов. Поэтому рекомендации по оптимизации должны быть адаптированы под конкретные условия и требования вашего проекта.
## CTE

[SQL Подзапросы и CTE (Postgres, Clickhouse)](SQL%20Подзапросы%20и%20CTE%20(Postgres,%20Clickhouse).md)
## Алгоритмы соединений
### Слиянием (merge join) [^12]

Подготовительный этап для соединения слияние служит сортировка **двух** выборок ($O(Nlog N$).

Далее соединение выполняется примерно по следующему алгоритму:
```
Читается запись первой выборки ->
Читается запись второй выборки ->
Сравниваются поля (поля для соединения), если они равны, то берется вторую строку второго набора.
Читаем строку того набора значение поля которого меньше ("Один набор догоняет другой").
Если же значения одинаковы, то читаем следующую строку второго набора.
```


>[!info] Если индексный доступ к таблице то этапа сортировки можно избежать.

>[!tip] Результат соединения слиянием возвращается в отсортированном виде, это может быть полезно при последующем новом соединении, не нужно будет сортировать.


Возможно параллельное выполнение алгоритма.
![](Pasted%20image%2020240412005812.png)
**Плюсы/Минусы:**
- Возможные начальные затраты на сортировку ➖;
* Эффективно для большого числа строк ➕;
* Поддерживает только эквисоединения ➖;

**Вычислительная сложность**
~ N+M, где N и M — число строк в первом и втором наборах данных, если не требуется сортировка ~ $NlogN+MlogM$, если сортировка нужна

**Применение:**
- Соединение слиянием может успешно применяться как в OLTP-, так и в OLAP-запросах.
- Однако если сортировка требуется, то стоимость становится пропорциональной произведению количества строк на логарифм этого количества, и на больших объемах такой способ скорее всего проиграет соединению хешированием.
- Эффективно для больших выборок;
### Сортировки

1. Сортировка в памяти;
	1. quick sort - быстрая сортировка;
	2. Частичная пирамидальная сортировка top-N heapsort - используется когда нужна только часть значений (limit);
	3. Инкриментальная сортировка - когда данные уже отсортированы, но не по всем ключам;
2. Внешняя сортировка - Набор строк читается в память, пока есть возможность, затем сортируется и записывается во временные файлы, далее происходит слияние файлов;
3. Группировки и уникальные значения при помощи сортировки;
4. Сортировка в параллельных планах;
![](Pasted%20image%2020240416230036.png)



### Соединение хэшированием (Hash join) [^11]

**Пример плана запроса соединения хешированием:**
```postgresql
EXPLAIN SELECT f.flight_id, bp.seat_no
FROM flights f
  JOIN boarding_passes bp ON bp.flight_id = f.flight_id;
                                    QUERY PLAN                                     
-----------------------------------------------------------------------------------
 Hash Join  (cost=8298.51..229403.28 rows=7925811 width=7)
   Hash Cond: (bp.flight_id = f.flight_id)
   ->  Seq Scan on boarding_passes bp  (cost=0.00..137537.11 rows=7925811 width=7)
   ->  Hash  (cost=4772.67..4772.67 rows=214867 width=4)
         ->  Seq Scan on flights f  (cost=0.00..4772.67 rows=214867 width=4)
(5 rows)
```

>[!danger] Рекомендации по работе с соединениями
>Нежелательное использование * обусловлено тем что при соединении большой выборки выполняется соединение хешированием и при первом проходе выборки строит хеш-таблица с цепочками переполнения по условиям соединения , хеш таблица имеет ограниченный размер. Наилучшая эффективность достигается если вся хеш-таблица помещается в выделенный объем. Поэтому важно использовать только необходимые поля.

#### Однопроходное соединение

Делается в два этапа:
Сперва строиться хеш-таблица с бакетам.
На втором этапе проходится вторая выборка и на лету считается хеш и ишется в хеш таблице, если есть то пара найдена (но не всегда, бывают коллизии).

#### Двухпроходное соединение
Применяется, когда хеш-таблица не помещается в оперативную память: наборы данных разбиваются на пакеты и последовательно соединяются.
![](Pasted%20image%2020240412003142.png)

Хеш-таблица для первого пакета остается в памяти, а строки, принадлежащие другим пакетам, сбрасываются на диск во временные файлы — каждый пакет в свой файл.

#### Parallel hash join

![](Pasted%20image%2020240412003725.png)
В отличие от других способов соединения, хеш-соединение не только может участвовать в параллельных планах, но и имеет отдельный эффективный алгоритм работы. Этот алгоритм позволяет параллельно выполнять оба этапа соединения: и построение хеш-таблицы по первому (внутреннему) набору строк, и сопоставление с ней строк второго (внешнего) набора.

**Пример для однопроходного соединения**:
![](Pasted%20image%2020240412003837.png)
Параллельные процессы проверяют по частям вторую выборку.

**Пример для двухпроходного соединения:**
Наборы строк разбиваются на пакеты, которые затем параллельно обрабатываются рабочими процессами.

![](Pasted%20image%2020240412004720.png)

**Примерный алгоритм работы:**
1. Параллельные процессы читают первый набор данных, разбивают его на пакеты и записывают в файлы (первый пакет тоже попадает в файл);
2. Параллельные процессы читают второй набор данных и также разбивают его на пакеты и записывают в файлы;
3. Каждый процесс выбирает себе по пакету;
4. Каждый пакет загружается в свою хеш-таблицу (доступ ко всем таблицам есть у всех процессов);
5. Процесс читает второй набор выбранного пакета и сопоставляет строки;

**Плюсы/Минусы:**
- Соединение хешированием требует подготовки, надо построить хеш-таблицу ➖;
* Эффективно для больших выборок в том числе есть возможность параллельного соединения ➕;
* Поддерживает только эквисоединения ➖;
* Зависит от порядка соединения, внутренний набор должен быть меньше внешнего, чтобы минимизировать хеш-таблицу ❔;

**Вычислительная сложность**
~ N+M, где N и M — число строк в первом и втором наборах данных.

**Применение**:
- Для большой выборки оптимизатор предпочитает соединение хешированием.



### Вложенными циклами (Nested loops) [^10]

**Модификации алгоритма:**
1. Левое соединение;
2. Антисоединение;
```sql
EXPLAIN (costs off) SELECT * 
FROM aircrafts a
  LEFT JOIN seats s ON (a.aircraft_code = s.aircraft_code) 
WHERE a.model LIKE 'Аэробус%'
AND s.aircraft_code IS NULL;
---

EXPLAIN (costs off) SELECT * 
FROM aircrafts a
WHERE a.model LIKE 'Аэробус%'
AND NOT EXISTS (
  SELECT * FROM seats s WHERE s.aircraft_code = a.aircraft_code
);
```

>[!important] Соединение вложенными циклами может выполняться параллельно
>_Правое соединение_ не поддерживается, поскольку для алгоритма вложенного цикла внешний и внутренний наборы строк неравнозначны. Внешний набор строк просматривается полностью, но из внутреннего при индексном доступе читаются только строки, удовлетворяющие условию соединения. При этом часть строк может остаться непросмотренной.

>[!danger] Правое соединение не поддерживается 

**Плюсы/Минусы:**
- Зависит от порядка соединения (обычно лучше, если внешний набор меньше внутреннего) ➖;
* Вложенный цикл не требует подготовительных действий - может отдавать результат соединения без задержек; ➕;
* Эффективен для небольших выборок (желательно чтобы к внутреннему был доступ по индексу) ➕;
* Поддерживает соединение по любому условию ➕;

**Вычислительная сложность**
~ N * M, где N и M — число строк в первом и втором наборах данных.

**Применение**: Эффективен для небольших выборок.

## Статистика [^14]

### Базовая статистика

Собирается на уровне таблиц и столбцов

Статистика на уровне столбцов хранится в **pg_statistic** и **pg_stats**.

Список наиболее частых значений и частота их встречаемости:
```postgresql
SELECT most_common_vals, most_common_freqs
FROM pg_stats
WHERE tablename = 'flights' AND attname = 'arrival_airport'
```

>[!tip] Частные планы запросов (Есть ещё общие планы запросов)
>Такие планы называются частными, поскольку они построены с учетом конкретных значений параметров.

Пять первых планирований всегда используют частные планы. Затем может оказаться, что стоимость общего плана (построенного без учета конкретного значения, в предположении равномерного распределения) не превышает среднюю стоимость уже построенных частных планов. Тогда планировщик запомнит общий план и будет использовать его, не выполняя планирование каждый раз.
При неравномерном распределении это может вызывать проблемы. Параметр **plan_cache_mode** позволяет отключить использование частных планов (или наоборот, с самого начала использовать общий план):
```postgresql
=> SHOW plan_cache_mode;

 plan_cache_mode 
-----------------
 auto
(1 row)

=> SET plan_cache_mode = 'force_custom_plan';

SET
```


| Статистика                   | Описание                                                     | Пример |
| ---------------------------- | ------------------------------------------------------------ | ------ |
| Число строк                  | Оценка кардинальности                                        |        |
| Доля неопределенных значений |                                                              |        |
| Наиболее частные значения    | Массив наиболее частых значений, массив частот этих значений |        |
| Число уникальных значений    |                                                              |        |
| ...                          | ...                                                          | ...    |

### Расширенная статистика

Можно создавать специальный объект для расширенной статистики командой CREATE STATISTICS.
Существует три вида многовариантной статистики (то есть статистики по нескольким столбцам таблицы), которые можно указать при создании объекта расширенной статистики.

#### Функциональные зависимости между столбцами
Такая статистика показывает, насколько данные в одном столбце определяются значением другого столбца. Она помогает улучшить оценку в случае коррелированных предикатов.

В случае если оптимизатор предполагает что два предиката поля между собой никак не связаны, он определяет общую селективность как произведение селективности двух полей.
Если мы уверены в корреляции двух полей то можно сообщить об этом планировщику.

```postgresql
=> CREATE STATISTICS flights_dep(dependencies)
ON flight_no, departure_airport FROM flights;

CREATE STATISTICS

=> ANALYZE flights;

ANALYZE

---

Собранная статистика хранится в следующем виде:

=> SELECT dependencies
FROM pg_stats_ext WHERE statistics_name = 'flights_dep';

               dependencies               
------------------------------------------
 {"2 => 5": 1.000000, "5 => 2": 0.011067}
(1 row)
```

#### Число уникальных комбинаций значений в столбцах.
Такая информация позволяет улучшить оценку кардинальности группировки по нескольким столбцам.
Другая ситуация, в которой планировщик ошибается с оценкой, связана с группировкой. Количество пар аэропортов, связанных прямыми рейсами, ограничено.
```postgresql
=> CREATE STATISTICS flights_nd(ndistinct)
  ON departure_airport, arrival_airport FROM flights;

CREATE STATISTICS

=> ANALYZE flights;

ANALYZE
```

#### Список наиболее частых комбинаций значений
Статистика помогает улучшить оценку условий, в которых проверяются значения нескольких столбцов.
При создании расширенной статистики можно указать любую комбинацию статистик и столбцов.

Начиная с версии PostgreSQL 12 можно строить расширенную статистику по частым комбинациям значений нескольких столбцов и использовать ее в запросах не только равенства, но и неравенства.
```postgresql
=> DROP STATISTICS flights_dep2;

DROP STATISTICS

=> CREATE STATISTICS flights_mcv(mcv)
ON departure_airport, aircraft_code FROM flights;

CREATE STATISTICS

=> ANALYZE flights;

ANALYZE
```

### Вывод

1. Характеристики данных собираются в виде статистики;
2. Статистика нужна для оценки кардинальности;
3. Кардинальность используется для оценки стоимости;
4. Стоимость позволяет выбрать оптимальный план;
5. Основа успеха —адекватная статистика и корректная кардинальность;


## Профилирование[^15]

### Инструменты

- Общий мониторинг (Graylog, Grafana, ...)
- pg_profile [^16]
- Database Lab Engine[^17]
- PL Profiler
- Журнал сообщений сервера [pgBadger]([https://github.com/darold/pgbadger](https://github.com/darold/pgbadger));
- Статистика [pg_stat_statements]([https://postgrespro.ru/docs/postgresql/13/pgstatstatements](https://postgrespro.ru/docs/postgresql/13/pgstatstatements));
- EXPLAIN ANALYZE;
### Метрики

Время выполнения - важно для клиента, крайне нестабильно.
Страничный вводы/вывод - стабилен по отношению ко внешним факторам. Мало информативен для пользователей.

### Области локализации

1. Клиентская часть;
2. Сервер приложений;
3. **Сервер баз данных**;
4. Сеть;


## Сложные запросы, их анализ и оптимизация. Приемы оптимизации[^18]


**Цель оптимизации:** получить адекватный план выполнения запроса.

>[!advice] Первый шаг к адекватному плану — актуальная статистика.
>Это достигается настройкой автоочистки и автоанализа.

>[!advice] Второй шаг к адекватному плану - настройка точности.
>Для увелечения точности может потребоваться изменить значение default_statistics_targer.
>Индекс по выражению с собственной статистикой.
>Использование расширенной статистики.
>

### Настройка стоимости

### Настройка стоимости ввода/вывода

>[!advice] Ввод-вывод можно (и нужно) указывать на уровне табличных пространств

С вводом-выводом связаны настройки, задающие веса для «условных единиц», в которых выражается стоимость.
Это параметры **seq_page_cost** и **random_page_cost**, определяющие стоимость чтения одной страницы при последовательном доступе и при произвольном доступе.
Значение **seq_page_cost** равно единице и его не стоит изменять.

>[!important] Высокое значение параметра **random_page_cost** отражает реалии HDD-дисков. Для SSD-дисков (а также в случаях, когда все данныес большой вероятностью будут закешированы), значение этого параметра необходимо значительно уменьшать, например, до 1.1.

Параметр effective_io_concurrency можно увеличить до числа независимых дисков в дисковом массиве. Фактически этот параметр влияет только на количество страниц, которые будут предварительно считаны в кеш при сканировании по битовой карте.

### Настройка стоимости времени процессора
```
Время процессора

cpu_tuple_cost = 0.01

cpu_index_tuple_cost = 0.005

cpu_operator_cost = 0.0025

CREATE FUNCTION … COST стоимость
```

### Настройка стоимости параллельного выполнения

```
Параллельное выполнение

parallel_setup_cost = 1000

parallel_tuple_cost = 0.1

Курсоры

cursor_tuple_fraction = 0.1
```

### Настройка памяти
```
Память

work_mem = 4MB

hash_mem_multiplier = 1

maintenance_work_mem = 64MB

effective_cache_size = 4GB
```


### Локализация настроек

```
На уровне табличного пространства

ALTER TABLESPACE SET …

На уровне базы данных

ALTER DATABASE SET …

На уровне роли и базы данных

ALTER ROLE [IN DATABASE …] SET …

На уровне процедуры или функции

ALTER ROUTINE SET …

На уровне сеанса или транзакции

SET [LOCAL] …
```

Часть параметров можно устанавливать на уровне отдельного сеанса или транзакции.
#### Пример
```postgresql
В ряде случаев может оказаться удобным оформить запросы в виде хранимых подпрограмм (например, с целью предоставить к ним доступ приложению). В этом случае дополнительным преимуществом может быть возможность установки параметров для конкретных подпрограмм.

Вот пример функции, возвращающей имена всех пассажиров с номерами рейсов за месяц в порядке возрастания даты вылета:

=> CREATE FUNCTION get_passengers_and_flights(d timestamptz)
RETURNS TABLE(passenger_name text, flight_no text)
AS $$
  SELECT t.passenger_name, f.flight_no
  FROM tickets t
    JOIN ticket_flights tf ON tf.ticket_no = t.ticket_no
    JOIN flights f ON f.flight_id = tf.flight_id
  WHERE f.scheduled_departure >= date_trunc('month', d)
    AND f.scheduled_departure  < date_trunc('month', d) + interval '1 month'
  ORDER BY f.scheduled_departure, t.passenger_name;
$$ LANGUAGE sql;

CREATE FUNCTION

Такая функция будет работать медленно из-за необходимости сортировки большого объема данных:

=> \timing on

Timing is on.

=> SELECT * FROM get_passengers_and_flights('2017-06-01') LIMIT 3;

    passenger_name    | flight_no 
----------------------+-----------
 ALBERT EGOROV        | PG0328
 ALEKSANDRA KUZNECOVA | PG0328
 ALEKSANDR BORISOV    | PG0328
(3 rows)

Time: 10027,995 ms (00:10,028)

Ситуацию можно немного улучшить, увеличив объем рабочей памяти для этого конкретного запроса:

=> ALTER FUNCTION get_passengers_and_flights SET work_mem = '32MB';

ALTER FUNCTION
Time: 5,904 ms

=> SELECT * FROM get_passengers_and_flights('2017-06-01') LIMIT 3;

    passenger_name    | flight_no 
----------------------+-----------
 ALBERT EGOROV        | PG0328
 ALEKSANDRA KUZNECOVA | PG0328
 ALEKSANDR BORISOV    | PG0328
(3 rows)

Time: 7654,217 ms (00:07,654)

=> \timing off

Timing is off.
```


### Схема данных

**Нормализация** — устранение избыточности в данных упрощает запросы и проверку согласованности
**Денормализация** — привнесение избыточности может повысить производительность, но требует синхронизации
**Индексы**
**Предрассчитанные поля** (генерируемые столбцы или триггеры)
**Материализованные представления**
**Кеширование результатов в приложении**
**Выбор подходящих типов** (составные типы (массивы, JSON) вместо отдельных таблиц)

### Физическое расположение

**Табличные пространства** - разнесение данных по разным физическим устройствам;
**Секционирование** - разделение таблицы на отдельно управляемые части для упрощения администрирования и ускорения доступа;
**Шардирование** - размещение секций на разных серверах для масштабирования нагрузки на чтение и запись секционирование и расширение postgres-fdw или сторонние решения


### Порядок соединений

>[!info] Автоматический выбор порядка соединений
если число соединяемых таблиц не превышает join_collapse_limit — планировщик выбирает лучший порядок соединений
при большем количестве рассматриваются не все варианты

>[!info] Ручное управление порядком соединений
материализация подзапросов с помощью CTE или временных таблиц
явные соединения (JOIN) и join_collapse_limit = 1
подзапросы в предложении FROM и from_collapse_limit = 1

### Материализация CTE

Подзапросы CTE могут быть материализованы. Материализацией управляет планировщик, но такое поведение можно гарантировать, указав ключевое слово MATERIALIZED. В этом случае подзапрос не раскрывается, его результат вычисляется и помещается либо в оперативную память (в пределах work_mem), либо сбрасывается во временный файл.

```sql
=> EXPLAIN (costs off)
WITH b AS MATERIALIZED (
  SELECT * FROM bookings
)
SELECT * FROM b
WHERE b.book_ref = '000112';

               QUERY PLAN                
-----------------------------------------
 CTE Scan on b
   Filter: (book_ref = '000112'::bpchar)
   CTE b
     ->  Seq Scan on bookings
(4 rows)

Теперь сначала вычисляется табличное выражение, и только затем — остальной запрос. В этом случае условие не может попасть внутри табличного выражения и индексный доступ не работает.
```


### Изменение запросов

>[!advice] Альтернативные способы выполнения
>планировщик не всегда рассматривает все возможные трансформации
>раскрытие коррелированных подзапросов
устранение лишних таблиц
замена UNION на OR и обратно
и т. п

>[!advice] Замена процедурного кода декларативным
чтобы избавиться от большого числа мелких запросов

Иногда требуются ручные изменения:
- Переписывание коррелированных подзапросов на соединения.
- Устранение из запроса лишних сканирований таблиц (например, за счет применения оконных функций).
- Использование недоступных планировщику трансформаций.
Например, операции для работы со множествами в настоящее время не трансформируются (UNION в OR и т. п.).

### Вывод

Доступен широкий спектр методов влияния на план выполнения запросов
Не все методы применимы во всех случаях
Методы, оказывающие глобальное влияние, следует применять с осторожностью
Ничто не заменит голову и здравый смысл
## Визуализация плана запроса

https://explain.dalibo.com/
## Источники

[^1]: https://postgrespro.ru/education/courses/QPT
[^2]:https://edu.postgrespro.ru/qpt-13/qpt_00_introduction.html
[^3]:https://postgrespro.ru/education/courses/QPT
[^4]:https://postgrespro.ru/docs/postgrespro/10/demodb-bookings-installation
[^5]:https://edu.postgrespro.ru/qpt-13/qpt_01_demo.html
[^6]:https://postgrespro.ru/docs/postgresql/12/sql-prepare
[^7]:https://edu.postgrespro.ru/qpt-13/qpt_03_seqscan.html
[^8]:https://edu.postgrespro.ru/qpt-13/qpt_04_indexscan.html
[^9]:https://edu.postgrespro.ru/qpt-13/qpt_05_bitmapscan.html
[^10]: https://edu.postgrespro.ru/qpt-13/qpt_06_nestloop.html
[^11]: https://edu.postgrespro.ru/qpt-13/qpt_07_hashjoin.html
[^12]:https://edu.postgrespro.ru/qpt-13/qpt_08_mergejoin.html
[^13]:https://habr.com/ru/articles/786024/
[^14]:https://edu.postgrespro.ru/qpt-13/qpt_09_statistics.html
[^15]:https://edu.postgrespro.ru/qpt-13/qpt_10_profiling.html
[^16]:https://tproger.ru/articles/kak-jeffektivno-analizirovat-statistiku-v-postgresql-s-pomoshhju-pg_profile
[^17]:https://habr.com/ru/articles/700368/
[^18]:https://edu.postgrespro.ru/qpt-13/qpt_11_technics.html
[^19]:https://habr.com/ru/companies/postgrespro/articles/579024/


[SQL Хранение и индексация](SQL%20Хранение%20и%20индексация.md)
[Mind Map SQL Запросы Продвинутый уровень](Mind%20Map%20SQL%20Запросы%20Продвинутый%20уровень.md)